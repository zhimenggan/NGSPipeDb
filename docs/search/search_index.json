{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NGSPipeDb - NGS pipeline and database Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Quick Start (5+6+7) - One time installation of components necessary and run test for typical application scenarios Step-by-Step RNA-seq analysis Installing wget and git Installing Miniconda3 Installing the NGSPipeDb conda environments Downloading the NGSPipeDb source code Downloading the NGSPipeDb test files Run test data Generate report Run your custome data Step-by-Step database generate Installing requirement Convert table file to sqlite3 Database config Start server Reproducibility Troubleshooting Introduction to NGSPipeDb NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser System requirements Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores. Anatomy of a NGSPipeDb project It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb. Quick Start - One time installation of components necessary for an individual user Three commands to start analysing test data: # download ngspipedb to anywhere you want git clone https://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_runtest.sh Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database . If you have more time, then we recommend you configure ngspipedb according to your needs. For more details, please see step by step bellow. Step-by-step RNA-seq workflow Although included in this section are step-by-step instructions, it is assumed that the user has a basic understanding of the nix command line interface . Also, best practice RNA-seq analysis is plus 1. Installing wget and git To get some of the required software packages, we will use the command line tools called wget and git . wget is a popular tool for downloading things off of the internet. git is a distributed version control system which we will use to checkout the NGSPipeDb code. Note : These tools are already pre-installed in most systems, but if you are unsure whether or not you have wget enter wget and if the return is wget: command not found , then you will have to install wget . Do likewise for git . 2. Installing Miniconda3 NGSPipeDb relies on the conda package manager for installation and dependency resolution, so you will need to install conda first. We will be using the Miniconda3 package management system (aka CONDA ) to manage all of the software packages that NGSPipeDb is dependent on. Use following commands to retrieve and then run the Minicoda3 installation script: 1. wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. bash Miniconda3-latest-Linux-x86_64.sh - While running the installation script, follow the commands listed on screen, and press the enter key to scroll. Make sure to answer yes when asked if you want to prepend Miniconda3 to PATH. - Close your terminal, open a new one and you should now have Conda working! You could, alternatively, run source ~/.bashrc to initiate conda. - Test by entering: conda update conda - Press y to confirm the conda updates 3. Mamba is a reimplementation of the conda package manager in C++, the fast conda-alternative. If you already have conda: - conda install mamba -c conda-forge Note : you will only have to install Minicoda3 once. 3. Downloading the NGSPipeDb project To install the latest stable version of NGSPipeDb, please clone the git repository to your system. cd /path/to/where_you_want git clone https://www.github.com/xuanblo/NGSPipeDb or cd /path/to/where_you_want git clone git://www.github.com/xuanblo/NGSPipeDb If you want to use specific version, please cleckout the release and issue the following commands: cd /path/to/where_you_want wget https://github.com/xuanblo/NGSPipeDb/archive/NGSPipeDb_xxx.tar.gz tar -xf NGSPipeDb_xxx.tar.gz Note : the xxx refers to the latest changeset of NGSPipeDb, so it will differ. 4. Installing the NGSPipeDb conda environments We are now ready to use conda to install the software packages which NGSPipeDb is dependent on. First, you will need to create the conda environments needed by the various workflows. The following command will create a new conda environment containing Snakemake and python called \"ngspipedb\" into which conda is installed, the default environment path is ~/miniconda/conda/env/ngspipedb . mamba create -c conda-forge -c bioconda --name ngspipedb snakemake python=3.8 Next, to analysis NGS data some bioinformatics tools need to be installed. mamba env update -n ngspipedb --file ngspipe/envs/requirement.yaml --prune Note : By default, all dependencies and tools should automatically be installed on the first execution. In case of download problems, please see how to install conda env local , share conda env for more detail. 5. Downloading the test files NGSPipeDb is dependent on reference files which can be found for the supported species listed below: download link To download RNA-seq test data into ./testdata , simply run the bash script download_testdata.sh : cd NGSPipeDb bash ngspipe/scripts/download_testdata.sh testdata` or you download the reference files that you need and then untarring then in a directory called testdata . wget http://www.liu-lab.com/ngspipedb/rnaseq_testdata.tar.gz tar -zxvf rnaseq_testdata.tar.gz Make sure you have the following directory structure by tree testdata : testdata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u251c\u2500\u2500 chr19.fa \u251c\u2500\u2500 control_R1.fq.gz \u251c\u2500\u2500 control_R2.fq.gz \u251c\u2500\u2500 samples.xls \u251c\u2500\u2500 treated_R1.fq.gz \u2514\u2500\u2500 treated_R2.fq.gz 6. run RNA-seq analysis on test data We provied a simple RNA-seq workflow for you to take a glance of NGSPipe. In RNA-seq analysis part, it contains 7 step analysis: 1. sampling data 2. raw reads qc 3. junction alignmnet 4. transcript assembly 5. quantification 6. statistic First, we need to check the workflow/path/file. This will not execute anything, but display what would be done. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -np If nothing goes wrong, you can generate a dag plot: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --dag|dot -Tpng > dag.png Now you can do RNA-seq analysis by juest one simply command. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j 10 The final data files are put in the folder results . Please check you result file tree -d -L 2 results/ , it may like this: results/ \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 1.rawreads_stat \u2502 \u251c\u2500\u2500 2.cleanreads_stat \u2502 \u251c\u2500\u2500 3.mapping_stat \u2502 \u251c\u2500\u2500 4.exp_stat \u2502 \u2514\u2500\u2500 workflow \u251c\u2500\u2500 result \u2502 \u251c\u2500\u2500 junction_align \u2502 \u251c\u2500\u2500 quantify \u2502 \u251c\u2500\u2500 rawReads_qc \u2502 \u251c\u2500\u2500 sampling_data \u2502 \u251c\u2500\u2500 statistic \u2502 \u2514\u2500\u2500 transcript_assembly \u2514\u2500\u2500 sqlite3 \u251c\u2500\u2500 blastdb \u251c\u2500\u2500 exp \u251c\u2500\u2500 gbrowse \u2514\u2500\u2500 gff_sqlite3 Note : If you encounter any problem in this step, please turn to TroubleShooting for help. 7. rgenerate report If all goes well, the proper analysis will be followed by the making of the html report using Snakemake to a html report file with pictures and tables. snakemake --snakefile ngspipe/rnaseq_analysis.Snakefile.py --report results/Report/report.html the final report should appear as results/Report/report.html . This report is a single html file with all in it and can be sent to customers/colleagues as a final report. It is nicer than a PDF version because of large tables and figures which would suffer from page breaks and it can be viewed on any device supporting html include smartphones :-). Note : Internet Explorer is not supported. If you get connected error in this step, you can solve this problem by edit file ngspipedb_py38_conda_env/lib/python3.8/site-packages/snakemake/report/report.html.jinja2 to change https://raw.githubusercontent.com/eligrey/FileSaver.js/2.0.0/src/FileSaver.js to https://cdnjs.cloudflare.com/ajax/libs/FileSaver.js/2.0.0/FileSaver.js 8. run your custome data NGSPipeDb is built to be used routinely. To ensure a maximum comparability of the results, a default config.yaml file is generated when calling the AQUAMIS.py wrapper script. The wrapper itself only allows configuring basic functionalities. The config.yaml can be initialized by starting AQUAMIS with the dry-run flag -n . Then, you can alter it to configure NGSPipeDb in more detail. Running this code requires: installing miniconda and all required dependencies from the provided environment.yaml ( conda env create --name pinfish_3.6 --file=environment.yaml ) editing the config.yaml file to match your own machine, reference genome, and data adding the required data files in due locations (matching the yaml) edit the Preamble.md file to include a text describing the 'Aim' of the experiment. This text will be added to the report as first section and is one of the two report sections that can be edited by the end-user. edit ngspipe/report/*.rst that will be added at the end of the report. run Snakemake with snakemake --use-conda -j <thread number> view the report hosted here rem: when something breaks the snake, or if you add more text/comments in the initial Rmd report, you can regenerate the report manually with R --slave -e 'rmarkdown::render(\"Nanopore_Pinfish_Analysis.Rmd\", \"html_document\")' within the base project folder. edit file NGSPipeCode/config.yaml for general data path or something. edit file snakefile for general data path or something. Configuring the META files: config.yaml The config.yaml file has three main sections. PATHS , PARAMS , SAMPLES : edit file NGSPipeCode/Snakefile for advance setting, such as sampling method, mapping tool, email address to receive run log. create samples.xls, for example, if you have two samples named \"control\" and \"treated\", just create a text file (maybe named sample.xls) with one column and two rows. resources/testdata/sample.info.xls: control treated Raw data files can either be fastq, fastq.gz, or bam formated files. If your raw data are located in somewhere else , you can copy them to rawdata , or create soft links like cd rawdata && ln -s yoursamplepath/*.fq.gz ./ . As recommended above, if all of your raw data are located in rawdata , then create a samples.xls file like: lung.rep1 lung.rep2 lung.rep3 liver.rep1 liver.rep2 liver.rep3 If you did not follow the recommended best practice then you will have to specify the full paths here. Each sample should be given a NAME (arbitrary text) and a PATH IMPORTANT : You cannot mix Paired-end and Single-end samples within the same VIPER run as this will cause an ERROR . If necessary, run all of one type of data first, followed by the net type of data after. 2. Copying over the META files: The META files ( config.yaml and metasheet.csv ) allow you to configure each run. They are explained in much more detail below. For now, we simply copy them from the viper source directory: cd PROJECT cp viper/config.yaml . cp viper/metasheet.csv . We will explain how to edit and configure these files shortly below In this section, you will need to specify the location of the following static reference files. The script path is always relative to the Snakefile containing the directive (in contrast to the input and output file paths, which are relative to the working directory). All paths in the snakefile are interpreted relative to the directory snakemake is executed in. 3. custom your snakefile 4. run # dry run, use -n parameter only print task plan, -p print commands snakemake -np --snakefile NGSPipeCode/Snakefile --configfile NGSPipeCode/config.yaml # run pipe snakemake -p --snakefile NGSPipeCode/Snakefile --configfile NGSPipeCode/config.yaml -j1 Note : Input, output and log are relative to your execution directory. Other paths, such as Env and include, are relative to the snapfile path Step-by-step database generate We use django project to constructed our NGSDb. We have pareparied many apps for you. \u5d4c\u5165. Please have a look: django apps description package home home page geneExpAtlas table network igv genome browse IGV blastplus ncbi blast + NCBI ngstools wooey efp efp browse clustergrammer-js https://clustergrammer.readthedocs.io/clustergrammer_js.html AQUAMIS will provide you with an interactive, browser-based report, showing the most important measures of your data on the first sight. All tables in the report can be sorted and filtered. The table on the first tab shows the key values for a quick estimation of the success of your sequencing experiment and the assembly. On the second tab, there is a more detailed table, giving many additional measures. Additionally to the tables, many measures are provided as graphical feedback. On the third tab, you see plots which are generated for one complete sequencing experiment. On the fourth tab, there are plots which each show measures on one specific dataset. 1. \u5b89\u88c5\u73af\u5883 django wooey clustergrammer sklearn pandas=0.25.3 2. convert analysis result to sqlite3 file modify model.py snakemake -s ngspipe/db_generate.Snakefile.py -p -j1 3. config \u4fee\u6539 mysite/mysite/settings.py # Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', # add custom app 'geneAnno', # gene annotation from nr/nt/pfam/go/kegg 'geneExpAtlas', # gene expression matrix 'blast', # blast tool ] 4. start server Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000. 5. add your custome data table data in a page custome script in wooey python manage.py makemigrations python manage.py migrate python manage.py addscript ../ngsdb/tools/test1.py If you want use wooey tools on a task model celery -A ProjectName worker -c 1 --beat -l info optional. reproducibility conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env --clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528--use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528--use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config --set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update --prefix ./ngspipedb_py38_conda_env/ --file requirement.yaml --prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html --conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba --conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 --conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py --use-conda --conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the --use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use --use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django Troubleshooting Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3 Contributing Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn )","title":"NGSPipeDb usage"},{"location":"#ngspipedb-ngs-pipeline-and-database","text":"Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Quick Start (5+6+7) - One time installation of components necessary and run test for typical application scenarios Step-by-Step RNA-seq analysis Installing wget and git Installing Miniconda3 Installing the NGSPipeDb conda environments Downloading the NGSPipeDb source code Downloading the NGSPipeDb test files Run test data Generate report Run your custome data Step-by-Step database generate Installing requirement Convert table file to sqlite3 Database config Start server Reproducibility Troubleshooting","title":"NGSPipeDb - NGS pipeline and database"},{"location":"#introduction-to-ngspipedb","text":"NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser","title":"Introduction to NGSPipeDb "},{"location":"#system-requirements","text":"Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores.","title":"System requirements "},{"location":"#anatomy-of-a-ngspipedb-project","text":"It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb.","title":"Anatomy of a NGSPipeDb project "},{"location":"#quick-start-one-time-installation-of-components-necessary-for-an-individual-user","text":"Three commands to start analysing test data: # download ngspipedb to anywhere you want git clone https://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_runtest.sh Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database . If you have more time, then we recommend you configure ngspipedb according to your needs. For more details, please see step by step bellow.","title":"Quick Start - One time installation of components necessary for an individual user "},{"location":"#step-by-step-rna-seq-workflow","text":"Although included in this section are step-by-step instructions, it is assumed that the user has a basic understanding of the nix command line interface . Also, best practice RNA-seq analysis is plus","title":"Step-by-step RNA-seq workflow "},{"location":"#1-installing-wget-and-git","text":"To get some of the required software packages, we will use the command line tools called wget and git . wget is a popular tool for downloading things off of the internet. git is a distributed version control system which we will use to checkout the NGSPipeDb code. Note : These tools are already pre-installed in most systems, but if you are unsure whether or not you have wget enter wget and if the return is wget: command not found , then you will have to install wget . Do likewise for git .","title":"1. Installing wget and git "},{"location":"#2-installing-miniconda3","text":"NGSPipeDb relies on the conda package manager for installation and dependency resolution, so you will need to install conda first. We will be using the Miniconda3 package management system (aka CONDA ) to manage all of the software packages that NGSPipeDb is dependent on. Use following commands to retrieve and then run the Minicoda3 installation script: 1. wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. bash Miniconda3-latest-Linux-x86_64.sh - While running the installation script, follow the commands listed on screen, and press the enter key to scroll. Make sure to answer yes when asked if you want to prepend Miniconda3 to PATH. - Close your terminal, open a new one and you should now have Conda working! You could, alternatively, run source ~/.bashrc to initiate conda. - Test by entering: conda update conda - Press y to confirm the conda updates 3. Mamba is a reimplementation of the conda package manager in C++, the fast conda-alternative. If you already have conda: - conda install mamba -c conda-forge Note : you will only have to install Minicoda3 once.","title":"2. Installing Miniconda3 "},{"location":"#3-downloading-the-ngspipedb-project","text":"To install the latest stable version of NGSPipeDb, please clone the git repository to your system. cd /path/to/where_you_want git clone https://www.github.com/xuanblo/NGSPipeDb or cd /path/to/where_you_want git clone git://www.github.com/xuanblo/NGSPipeDb If you want to use specific version, please cleckout the release and issue the following commands: cd /path/to/where_you_want wget https://github.com/xuanblo/NGSPipeDb/archive/NGSPipeDb_xxx.tar.gz tar -xf NGSPipeDb_xxx.tar.gz Note : the xxx refers to the latest changeset of NGSPipeDb, so it will differ.","title":"3. Downloading the NGSPipeDb project "},{"location":"#4-installing-the-ngspipedb-conda-environments","text":"We are now ready to use conda to install the software packages which NGSPipeDb is dependent on. First, you will need to create the conda environments needed by the various workflows. The following command will create a new conda environment containing Snakemake and python called \"ngspipedb\" into which conda is installed, the default environment path is ~/miniconda/conda/env/ngspipedb . mamba create -c conda-forge -c bioconda --name ngspipedb snakemake python=3.8 Next, to analysis NGS data some bioinformatics tools need to be installed. mamba env update -n ngspipedb --file ngspipe/envs/requirement.yaml --prune Note : By default, all dependencies and tools should automatically be installed on the first execution. In case of download problems, please see how to install conda env local , share conda env for more detail.","title":"4. Installing the NGSPipeDb conda environments "},{"location":"#5-downloading-the-test-files","text":"NGSPipeDb is dependent on reference files which can be found for the supported species listed below: download link To download RNA-seq test data into ./testdata , simply run the bash script download_testdata.sh : cd NGSPipeDb bash ngspipe/scripts/download_testdata.sh testdata` or you download the reference files that you need and then untarring then in a directory called testdata . wget http://www.liu-lab.com/ngspipedb/rnaseq_testdata.tar.gz tar -zxvf rnaseq_testdata.tar.gz Make sure you have the following directory structure by tree testdata : testdata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u251c\u2500\u2500 chr19.fa \u251c\u2500\u2500 control_R1.fq.gz \u251c\u2500\u2500 control_R2.fq.gz \u251c\u2500\u2500 samples.xls \u251c\u2500\u2500 treated_R1.fq.gz \u2514\u2500\u2500 treated_R2.fq.gz","title":"5. Downloading the test files "},{"location":"#6-run-rna-seq-analysis-on-test-data","text":"We provied a simple RNA-seq workflow for you to take a glance of NGSPipe. In RNA-seq analysis part, it contains 7 step analysis: 1. sampling data 2. raw reads qc 3. junction alignmnet 4. transcript assembly 5. quantification 6. statistic First, we need to check the workflow/path/file. This will not execute anything, but display what would be done. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -np If nothing goes wrong, you can generate a dag plot: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --dag|dot -Tpng > dag.png Now you can do RNA-seq analysis by juest one simply command. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j 10 The final data files are put in the folder results . Please check you result file tree -d -L 2 results/ , it may like this: results/ \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 1.rawreads_stat \u2502 \u251c\u2500\u2500 2.cleanreads_stat \u2502 \u251c\u2500\u2500 3.mapping_stat \u2502 \u251c\u2500\u2500 4.exp_stat \u2502 \u2514\u2500\u2500 workflow \u251c\u2500\u2500 result \u2502 \u251c\u2500\u2500 junction_align \u2502 \u251c\u2500\u2500 quantify \u2502 \u251c\u2500\u2500 rawReads_qc \u2502 \u251c\u2500\u2500 sampling_data \u2502 \u251c\u2500\u2500 statistic \u2502 \u2514\u2500\u2500 transcript_assembly \u2514\u2500\u2500 sqlite3 \u251c\u2500\u2500 blastdb \u251c\u2500\u2500 exp \u251c\u2500\u2500 gbrowse \u2514\u2500\u2500 gff_sqlite3 Note : If you encounter any problem in this step, please turn to TroubleShooting for help.","title":"6. run RNA-seq analysis on test data "},{"location":"#7-rgenerate-report","text":"If all goes well, the proper analysis will be followed by the making of the html report using Snakemake to a html report file with pictures and tables. snakemake --snakefile ngspipe/rnaseq_analysis.Snakefile.py --report results/Report/report.html the final report should appear as results/Report/report.html . This report is a single html file with all in it and can be sent to customers/colleagues as a final report. It is nicer than a PDF version because of large tables and figures which would suffer from page breaks and it can be viewed on any device supporting html include smartphones :-). Note : Internet Explorer is not supported. If you get connected error in this step, you can solve this problem by edit file ngspipedb_py38_conda_env/lib/python3.8/site-packages/snakemake/report/report.html.jinja2 to change https://raw.githubusercontent.com/eligrey/FileSaver.js/2.0.0/src/FileSaver.js to https://cdnjs.cloudflare.com/ajax/libs/FileSaver.js/2.0.0/FileSaver.js","title":"7. rgenerate report "},{"location":"#8-run-your-custome-data","text":"NGSPipeDb is built to be used routinely. To ensure a maximum comparability of the results, a default config.yaml file is generated when calling the AQUAMIS.py wrapper script. The wrapper itself only allows configuring basic functionalities. The config.yaml can be initialized by starting AQUAMIS with the dry-run flag -n . Then, you can alter it to configure NGSPipeDb in more detail. Running this code requires: installing miniconda and all required dependencies from the provided environment.yaml ( conda env create --name pinfish_3.6 --file=environment.yaml ) editing the config.yaml file to match your own machine, reference genome, and data adding the required data files in due locations (matching the yaml) edit the Preamble.md file to include a text describing the 'Aim' of the experiment. This text will be added to the report as first section and is one of the two report sections that can be edited by the end-user. edit ngspipe/report/*.rst that will be added at the end of the report. run Snakemake with snakemake --use-conda -j <thread number> view the report hosted here rem: when something breaks the snake, or if you add more text/comments in the initial Rmd report, you can regenerate the report manually with R --slave -e 'rmarkdown::render(\"Nanopore_Pinfish_Analysis.Rmd\", \"html_document\")' within the base project folder. edit file NGSPipeCode/config.yaml for general data path or something. edit file snakefile for general data path or something. Configuring the META files: config.yaml The config.yaml file has three main sections. PATHS , PARAMS , SAMPLES : edit file NGSPipeCode/Snakefile for advance setting, such as sampling method, mapping tool, email address to receive run log. create samples.xls, for example, if you have two samples named \"control\" and \"treated\", just create a text file (maybe named sample.xls) with one column and two rows. resources/testdata/sample.info.xls: control treated Raw data files can either be fastq, fastq.gz, or bam formated files. If your raw data are located in somewhere else , you can copy them to rawdata , or create soft links like cd rawdata && ln -s yoursamplepath/*.fq.gz ./ . As recommended above, if all of your raw data are located in rawdata , then create a samples.xls file like: lung.rep1 lung.rep2 lung.rep3 liver.rep1 liver.rep2 liver.rep3 If you did not follow the recommended best practice then you will have to specify the full paths here. Each sample should be given a NAME (arbitrary text) and a PATH IMPORTANT : You cannot mix Paired-end and Single-end samples within the same VIPER run as this will cause an ERROR . If necessary, run all of one type of data first, followed by the net type of data after. 2. Copying over the META files: The META files ( config.yaml and metasheet.csv ) allow you to configure each run. They are explained in much more detail below. For now, we simply copy them from the viper source directory: cd PROJECT cp viper/config.yaml . cp viper/metasheet.csv . We will explain how to edit and configure these files shortly below In this section, you will need to specify the location of the following static reference files. The script path is always relative to the Snakefile containing the directive (in contrast to the input and output file paths, which are relative to the working directory). All paths in the snakefile are interpreted relative to the directory snakemake is executed in. 3. custom your snakefile 4. run # dry run, use -n parameter only print task plan, -p print commands snakemake -np --snakefile NGSPipeCode/Snakefile --configfile NGSPipeCode/config.yaml # run pipe snakemake -p --snakefile NGSPipeCode/Snakefile --configfile NGSPipeCode/config.yaml -j1 Note : Input, output and log are relative to your execution directory. Other paths, such as Env and include, are relative to the snapfile path","title":"8. run your custome data "},{"location":"#step-by-step-database-generate","text":"We use django project to constructed our NGSDb. We have pareparied many apps for you. \u5d4c\u5165. Please have a look: django apps description package home home page geneExpAtlas table network igv genome browse IGV blastplus ncbi blast + NCBI ngstools wooey efp efp browse clustergrammer-js https://clustergrammer.readthedocs.io/clustergrammer_js.html AQUAMIS will provide you with an interactive, browser-based report, showing the most important measures of your data on the first sight. All tables in the report can be sorted and filtered. The table on the first tab shows the key values for a quick estimation of the success of your sequencing experiment and the assembly. On the second tab, there is a more detailed table, giving many additional measures. Additionally to the tables, many measures are provided as graphical feedback. On the third tab, you see plots which are generated for one complete sequencing experiment. On the fourth tab, there are plots which each show measures on one specific dataset.","title":"Step-by-step database generate "},{"location":"#1","text":"django wooey clustergrammer sklearn pandas=0.25.3","title":"1. \u5b89\u88c5\u73af\u5883 "},{"location":"#2-convert-analysis-result-to-sqlite3-file","text":"modify model.py snakemake -s ngspipe/db_generate.Snakefile.py -p -j1","title":"2. convert analysis result to sqlite3 file "},{"location":"#3-config","text":"\u4fee\u6539 mysite/mysite/settings.py # Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', # add custom app 'geneAnno', # gene annotation from nr/nt/pfam/go/kegg 'geneExpAtlas', # gene expression matrix 'blast', # blast tool ]","title":"3. config "},{"location":"#4-start-server","text":"Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000.","title":"4. start server "},{"location":"#5-add-your-custome-data","text":"table data in a page custome script in wooey python manage.py makemigrations python manage.py migrate python manage.py addscript ../ngsdb/tools/test1.py If you want use wooey tools on a task model celery -A ProjectName worker -c 1 --beat -l info optional.","title":"5. add your custome data"},{"location":"#reproducibility","text":"conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env --clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528--use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528--use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config --set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update --prefix ./ngspipedb_py38_conda_env/ --file requirement.yaml --prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html --conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba --conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 --conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py --use-conda --conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the --use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use --use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django","title":"reproducibility "},{"location":"#troubleshooting","text":"Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3","title":"Troubleshooting "},{"location":"#contributing","text":"Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn )","title":"Contributing"},{"location":"linux/","text":"Basic knowledge of Linux 1.The absolute path is identified by a forward slash (/), which is different from the Windows operating system 2.How to use linux command: enter the command at the shell prompt: \"$\" . Command like: [Path]/command [-option parameter] [file|directory] For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz 3.The cd command is used to switch the directory where the session is located. Command like: cd directory For example: cd /usr/bin 4.The pwd command is used to view the directory where the current session is located, command like: pwd For example: pwd 5.Enter a single dot (.) to indicate the current directory, and enter a double dot (..) to indicate the parent directory of the current directory 6.Use the man command to view the operation manual of all required commands, command like: man command name For example: man cp 7.Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed For example: ls -l my_file This command specifies the relevant information of the output file my_file When writing a filter, you can use a question mark (?) to represent a character, an asterisk (*) to represent zero or more characters, and use the tab key (Tab) to quickly complete the file name or directory First name 8.The which command is used to find the path of the command. Command like: which grep For example: which fastp About permission View the file permission When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining 9 letters are grouped into 3, representing the permissions for the owner, the permissions for the owner's group, and the permissions for other groups. r means read-only; w means allowing user to modify the content of the file; x means allowing user to execute the file as a program; - means user having no such permission Modify permissions: chmod command You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt Command about directory 1.Check what files are in the directory-list function (1) Basic list function: ls command command like: ls various parameters directory name --F distinguish between files and directories --R recursive option to list files in subdirectories contained in the current directory --l produces a long list of output results, including information about each file --d lists only the information of the directory itself, not its contents --i The inode number of the file, which is the unique identifier of the file --a Display both hidden files and ordinary files The parameters can be combined and written, for example: ls -Fd (2) The way to output the tree list: tree tool The tool needs to be downloaded by yourself. command like: tree filter 2.Create a directory: mkdir command command like: mkdir directory name To create multiple directories and subdirectories, you can use the -p parameter, for example: mkdir -p New_file/work/file1 The -p parameter in the mkdir command can create missing parent directories as needed 3.Delete directory: rmdir command command like: $ rmdir parameter directory name --No parameters after rmdir delete empty directories --rf delete all contents in the directory --i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct Command about file 1.Create a file: touch command Command like: touch parameter file name -Create a new file without adding parameters after touch, if the file already exists, change the modification time -a Change the access time of an existing file 2.Delete files: rm command Command like: rm -i file name Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct 3.Copy files: cp command Command like: cp [parameter] [file name] --i Force to ask if you need to overwrite existing files --R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter 4.Rename and move files: mv command (1) Rename command like: mv [original file name] [new file name] (2) Move command like: mv file name in the original path, target new path (3) Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook Move the book file in the picture folder to the file folder and rename it to cook 5.View files <1> View file type: file command command like: file file name You can check the file type, character encoding method, whether the file can be run, etc. <2> View the entire file (1) cat command: display all data in the text file command like: cat parameter file name --No parameters after cat display content --n display content after adding line number --b displays only after adding line numbers to text content --T does not display tabs, replace tabs with ^T to display (2) More command: display the content of the text file, but it will stop after each page is displayed (3) less command: display the content of text files and support more advanced interaction <3> View some files (1) head command: view the beginning of the file command like: head -n file name n is the number of rows displayed (2) tail command: view the end of the file command like: tail -n file name n is the number of rows displayed <4> Upload files, download files (1) rz file name: upload file (2) sz file name: download file Command about process 1.Probe the process (1) ps command command like: ps parameter Symbol description: -PID process ID -Terminal device when TTY process starts -TIME Cumulative CPU time required by the process -The name of the program started by CMD (2) top command command like: top Symbol description: -load average The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. -PR process priority -Moderate value of NI process -The total amount of virtual memory occupied by the VIRT process -The total amount of physical memory occupied by the RES process -%MEM The ratio of memory used by the process to available memory -S process state (D: interruptible sleep state, R: running, S: sleeping, T: tracking or stopping state, Z: rigid state) (3) The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information. 2.End the process (1) kill command command like: kill PID or kill -s process signal (2) killall command command like: killall process name Use wildcards carefully in the killall command Execute tasks to the background Method 1: [Path]/command [-option parameter] [file|directory] & Method 2: nohup [path]/command [-option parameter] [file|directory] & Method 3: screen command Command like : (1)Create a screen: screen -dmS screen_test (2)View the screen: screen -list (3)Connect to the screen: screen -r screen_test Common task management commands: (1)jobs: View tasks, return task number n and process number (2)bg %n: Transfer task number n to the background (3)fg %n: Transfer task number n to the foreground (4)ctrl+z: Suspend the current task (5)ctrl+c: Stop the current task (6)kill -n task: End the task Command about disk space 1.Mount the device: mount command command like: mount parameter file device type device to be mounted target location File device types are: -vfat: Windows long file system -ntfs: an advanced file system widely used in Windows -iso9660: Standard CD-ROM file system 2.Uninstall the device: umount command command like: umount location/target device 3.Explore the disk situation (1) df command command like: df [parameter] [target disk] (2) du command command like: du [parameter] [target disk] --c displays the total size of all listed files --h Display in a user-readable way --s displays the total of each output parameter (3) The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file 4.Disk partition: fdisk command command like: fdisk -l [disk name] 5.Disk formatting: mkfs command command like: mksf -t file [system format] [parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat 6.Disk verification: fsck command command like: fsck -t file [system format] [parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat Case 1.Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz 2.Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz 3.Install the software: (1)cd soft (2)./configure (3)make (4)make install 4.Update PATH: (1) Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc (2)Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH (3)Update environment variables: source ~/.bashrc","title":"Linux basic"},{"location":"linux/#basic-knowledge-of-linux","text":"1.The absolute path is identified by a forward slash (/), which is different from the Windows operating system 2.How to use linux command: enter the command at the shell prompt: \"$\" . Command like: [Path]/command [-option parameter] [file|directory] For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz 3.The cd command is used to switch the directory where the session is located. Command like: cd directory For example: cd /usr/bin 4.The pwd command is used to view the directory where the current session is located, command like: pwd For example: pwd 5.Enter a single dot (.) to indicate the current directory, and enter a double dot (..) to indicate the parent directory of the current directory 6.Use the man command to view the operation manual of all required commands, command like: man command name For example: man cp 7.Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed For example: ls -l my_file This command specifies the relevant information of the output file my_file When writing a filter, you can use a question mark (?) to represent a character, an asterisk (*) to represent zero or more characters, and use the tab key (Tab) to quickly complete the file name or directory First name 8.The which command is used to find the path of the command. Command like: which grep For example: which fastp","title":"Basic knowledge of Linux"},{"location":"linux/#about-permission","text":"","title":"About permission"},{"location":"linux/#view-the-file-permission","text":"When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining 9 letters are grouped into 3, representing the permissions for the owner, the permissions for the owner's group, and the permissions for other groups. r means read-only; w means allowing user to modify the content of the file; x means allowing user to execute the file as a program; - means user having no such permission","title":"View the file permission"},{"location":"linux/#modify-permissions-chmod-command","text":"You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt","title":"Modify permissions: chmod command"},{"location":"linux/#command-about-directory","text":"1.Check what files are in the directory-list function (1) Basic list function: ls command command like: ls various parameters directory name --F distinguish between files and directories --R recursive option to list files in subdirectories contained in the current directory --l produces a long list of output results, including information about each file --d lists only the information of the directory itself, not its contents --i The inode number of the file, which is the unique identifier of the file --a Display both hidden files and ordinary files The parameters can be combined and written, for example: ls -Fd (2) The way to output the tree list: tree tool The tool needs to be downloaded by yourself. command like: tree filter 2.Create a directory: mkdir command command like: mkdir directory name To create multiple directories and subdirectories, you can use the -p parameter, for example: mkdir -p New_file/work/file1 The -p parameter in the mkdir command can create missing parent directories as needed 3.Delete directory: rmdir command command like: $ rmdir parameter directory name --No parameters after rmdir delete empty directories --rf delete all contents in the directory --i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct","title":"Command about directory"},{"location":"linux/#command-about-file","text":"1.Create a file: touch command Command like: touch parameter file name -Create a new file without adding parameters after touch, if the file already exists, change the modification time -a Change the access time of an existing file 2.Delete files: rm command Command like: rm -i file name Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct 3.Copy files: cp command Command like: cp [parameter] [file name] --i Force to ask if you need to overwrite existing files --R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter 4.Rename and move files: mv command (1) Rename command like: mv [original file name] [new file name] (2) Move command like: mv file name in the original path, target new path (3) Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook Move the book file in the picture folder to the file folder and rename it to cook 5.View files <1> View file type: file command command like: file file name You can check the file type, character encoding method, whether the file can be run, etc. <2> View the entire file (1) cat command: display all data in the text file command like: cat parameter file name --No parameters after cat display content --n display content after adding line number --b displays only after adding line numbers to text content --T does not display tabs, replace tabs with ^T to display (2) More command: display the content of the text file, but it will stop after each page is displayed (3) less command: display the content of text files and support more advanced interaction <3> View some files (1) head command: view the beginning of the file command like: head -n file name n is the number of rows displayed (2) tail command: view the end of the file command like: tail -n file name n is the number of rows displayed <4> Upload files, download files (1) rz file name: upload file (2) sz file name: download file","title":"Command about file"},{"location":"linux/#command-about-process","text":"1.Probe the process (1) ps command command like: ps parameter Symbol description: -PID process ID -Terminal device when TTY process starts -TIME Cumulative CPU time required by the process -The name of the program started by CMD (2) top command command like: top Symbol description: -load average The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. -PR process priority -Moderate value of NI process -The total amount of virtual memory occupied by the VIRT process -The total amount of physical memory occupied by the RES process -%MEM The ratio of memory used by the process to available memory -S process state (D: interruptible sleep state, R: running, S: sleeping, T: tracking or stopping state, Z: rigid state) (3) The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information. 2.End the process (1) kill command command like: kill PID or kill -s process signal (2) killall command command like: killall process name Use wildcards carefully in the killall command","title":"Command about process"},{"location":"linux/#execute-tasks-to-the-background","text":"Method 1: [Path]/command [-option parameter] [file|directory] & Method 2: nohup [path]/command [-option parameter] [file|directory] & Method 3: screen command Command like : (1)Create a screen: screen -dmS screen_test (2)View the screen: screen -list (3)Connect to the screen: screen -r screen_test Common task management commands: (1)jobs: View tasks, return task number n and process number (2)bg %n: Transfer task number n to the background (3)fg %n: Transfer task number n to the foreground (4)ctrl+z: Suspend the current task (5)ctrl+c: Stop the current task (6)kill -n task: End the task","title":"Execute tasks to the background"},{"location":"linux/#command-about-disk-space","text":"1.Mount the device: mount command command like: mount parameter file device type device to be mounted target location File device types are: -vfat: Windows long file system -ntfs: an advanced file system widely used in Windows -iso9660: Standard CD-ROM file system 2.Uninstall the device: umount command command like: umount location/target device 3.Explore the disk situation (1) df command command like: df [parameter] [target disk] (2) du command command like: du [parameter] [target disk] --c displays the total size of all listed files --h Display in a user-readable way --s displays the total of each output parameter (3) The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file 4.Disk partition: fdisk command command like: fdisk -l [disk name] 5.Disk formatting: mkfs command command like: mksf -t file [system format] [parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat 6.Disk verification: fsck command command like: fsck -t file [system format] [parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat","title":"Command about disk space"},{"location":"linux/#case","text":"1.Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz 2.Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz 3.Install the software: (1)cd soft (2)./configure (3)make (4)make install 4.Update PATH: (1) Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc (2)Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH (3)Update environment variables: source ~/.bashrc","title":"Case"},{"location":"rnaseq/","text":"nature protocol","title":"RNA-seq best practice"},{"location":"rnaseq/#nature-protocol","text":"","title":"nature protocol"}]}