{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NGSPipeDb - NGS pipeline and database Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. What can NGSPipeDb do NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser Contributing Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn ) Resources","title":"Getting start"},{"location":"#ngspipedb-ngs-pipeline-and-database","text":"Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation.","title":"NGSPipeDb - NGS pipeline and database"},{"location":"#what-can-ngspipedb-do","text":"NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser","title":"What can NGSPipeDb do "},{"location":"#contributing","text":"Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn )","title":"Contributing"},{"location":"#resources","text":"","title":"Resources"},{"location":"NGSDb/","text":"NGSDb one step to view the NGSPipe RNA-Seq analysis results in a browser bash ngspipe/scripts/one_step_view_database.sh test Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database . Step-by-step to generate database with test data 1. pre-prepare Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb 2. Install the NGSDb conda environments mamba create -n ngsdb python = 3 .8 -c conda-forge -y mamba env update -n ngsdb --file ngspipe/envs/requirements_ngsdb.yaml --prune conda activate ngsdb 3. download test data mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/gene_fpkm_all_samples.tsv ./ wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz ./ gunzip chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/GRCm38.83.chr19.gtf.gz ./ gunzip GRCm38.83.chr19.gtf.gz cd .. 4. run convert testdata to database cheak task plan: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -n build dag plot: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml --dag | dot -Tpng > dag.png run snakemake: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -j 1 5. vist website Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000. generate database by you own data 1. convert NGSPipe analysis results to sqlite3 format First, edit ngspipe/config/ngsdb.config.yaml file: # path relative to where you run snakemake # gene structure annotation genomeAnno : \"testdata/GRCm38.83.chr19.gtf\" # gene annotation file, can be gtf or gff genomeFasta : \"testdata/chr19.fa\" # genome sequence # result directory of NGSPipe #testdata_resultsDir: \"results/result\" #estdata_reportsDir: \"results/report\" dbDir : \"results/sqlite3\" djangoCode : \"ngsdb\" exp_data : \"results/result/quantify/quantify_by_stringtie/gene_fpkm_all_samples.tsv\" report_path : \"\" gbrowse_data : \"\" # sample list file samplesList : \"testdata/samples.xls\" # sample file directory samplesDir : \"testdata\" # fastq suffix, read1 read1Suffix : \"_R1.fq.gz\" read2Suffix : \"_R2.fq.gz\" # replict can by 1,2,3 replict_num : 3 # condition for differential expression by deseq2 Second, edit ngspipe/workflow/db_generate.Snakefile.py file: # detail parameters in pipe # # 5. quantification quantify_method = 'stringtie' # htseqcounts or featurecounts quantify_outdir = join ( config [ \"resultsDir\" ], \"quantify\" , \"quantify_by_ {} \" . format ( quantify_method )) # 4. transcript assembly transcript_assembly_method = 'stringtie' # star transcript_assembly_outdir = join ( config [ \"resultsDir\" ], \"transcript_assembly\" , \"transcript_assembly_by_ {} \" . format ( transcript_assembly_method )) # blast # 1. expression matrix database create exp_db_outdir = join ( config [ \"dbDir\" ], \"exp\" ) anno_db_outdir = join ( config [ \"dbDir\" ], \"anno\" ) # sqlite3 # 2. blastdb blastdb_outdir = join ( config [ \"dbDir\" ], \"blastdb\" ) # 3. gffutils gffdb_outdir = join ( config [ \"dbDir\" ], \"gff_sqlite3\" ) # 4. genomebrowse gbrowse_outdir = join ( config [ \"dbDir\" ], \"gbrowse\" ) annotation_gbrowse_outdir = join ( gbrowse_outdir , 'annotation' ) # include modules include : join ( \"rules\" , \"8.db_generate_of_exp.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_gff.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_blastdb.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_genomebrowser.Snakefile.py\" ) Then, run db_generate workflow to generate database files. snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -j 1 2. config edit mysite/mysite/settings.py file # Application definition INSTALLED_APPS = [ 'django.contrib.admin' , 'django.contrib.auth' , 'django.contrib.contenttypes' , 'django.contrib.sessions' , 'django.contrib.messages' , 'django.contrib.staticfiles' , # add custom app 'geneAnno' , # gene annotation from nr/nt/pfam/go/kegg 'geneExpAtlas' , # gene expression matrix 'blast' , # blast tool ] 3. start server Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000. 4. add your custome data Let's assume that you have the data you need to generate the database, such as gene annotation files, gene expression matrix and analysis reports. Before further steps, please install CONDA and download the latest source code of NGSPipeDb . Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb table data in a page custome script in wooey python manage.py makemigrations python manage.py migrate python manage.py addscript ../ngsdb/tools/test1.py If you want use wooey tools on a task model celery -A ProjectName worker -c 1 --beat -l info optional. \u6dfb\u52a0script \u56e0\u4e3a\u8fd0\u884cscript\u7684\u65f6\u5019\u662f\u4f7f\u7528\u7edd\u5bf9\u8def\u5f84\uff0c\u90a3\u4e48addscript\u7684\u65f6\u5019\u548c\u8fd0\u884cscript\u7684\u65f6\u5019\u6587\u4ef6\u8def\u5f84\u5fc5\u987b\u4e0d\u80fd\u53d8\u3002\u5982\u4f55\u53d8\u6210\u76f8\u5bf9\u8def\u5f84\u5462\uff1f\u53e6\u5916\u5728admin\u7ba1\u7406\u9875\u9762script\u4e5f\u4e0d\u80fd\u76f4\u63a5\u8bbf\u95ee\u7684\u3002 5. overview the NGSDb apps We use django project to constructed our NGSDb. We have pareparied many apps for you. embeed. Please have a look: django apps description package report ngs analysis report snakemake geneExpAtlas table datatable js network table datatable js igv genome browse IGV blastplus ncbi blast + NCBI ngstools python script wooey efp efp browse heatmap expression clustergrammer-js https://clustergrammer.readthedocs.io/clustergrammer_js.html","title":"NGSDb"},{"location":"NGSDb/#ngsdb","text":"","title":"NGSDb"},{"location":"NGSDb/#one-step-to-view-the-ngspipe-rna-seq-analysis-results-in-a-browser","text":"bash ngspipe/scripts/one_step_view_database.sh test Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . - Example of database .","title":"one step to view the NGSPipe RNA-Seq analysis results in a browser"},{"location":"NGSDb/#step-by-step-to-generate-database-with-test-data","text":"","title":"Step-by-step to generate database with test data "},{"location":"NGSDb/#1-pre-prepare","text":"Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb","title":"1. pre-prepare"},{"location":"NGSDb/#2-install-the-ngsdb-conda-environments","text":"mamba create -n ngsdb python = 3 .8 -c conda-forge -y mamba env update -n ngsdb --file ngspipe/envs/requirements_ngsdb.yaml --prune conda activate ngsdb","title":"2. Install the NGSDb conda environments "},{"location":"NGSDb/#3-download-test-data","text":"mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/gene_fpkm_all_samples.tsv ./ wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz ./ gunzip chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/GRCm38.83.chr19.gtf.gz ./ gunzip GRCm38.83.chr19.gtf.gz cd ..","title":"3. download test data"},{"location":"NGSDb/#4-run-convert-testdata-to-database","text":"cheak task plan: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -n build dag plot: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml --dag | dot -Tpng > dag.png run snakemake: snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -j 1","title":"4. run convert testdata to database"},{"location":"NGSDb/#5-vist-website","text":"Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000.","title":"5. vist website"},{"location":"NGSDb/#generate-database-by-you-own-data","text":"","title":"generate database by you own data"},{"location":"NGSDb/#1-convert-ngspipe-analysis-results-to-sqlite3-format","text":"First, edit ngspipe/config/ngsdb.config.yaml file: # path relative to where you run snakemake # gene structure annotation genomeAnno : \"testdata/GRCm38.83.chr19.gtf\" # gene annotation file, can be gtf or gff genomeFasta : \"testdata/chr19.fa\" # genome sequence # result directory of NGSPipe #testdata_resultsDir: \"results/result\" #estdata_reportsDir: \"results/report\" dbDir : \"results/sqlite3\" djangoCode : \"ngsdb\" exp_data : \"results/result/quantify/quantify_by_stringtie/gene_fpkm_all_samples.tsv\" report_path : \"\" gbrowse_data : \"\" # sample list file samplesList : \"testdata/samples.xls\" # sample file directory samplesDir : \"testdata\" # fastq suffix, read1 read1Suffix : \"_R1.fq.gz\" read2Suffix : \"_R2.fq.gz\" # replict can by 1,2,3 replict_num : 3 # condition for differential expression by deseq2 Second, edit ngspipe/workflow/db_generate.Snakefile.py file: # detail parameters in pipe # # 5. quantification quantify_method = 'stringtie' # htseqcounts or featurecounts quantify_outdir = join ( config [ \"resultsDir\" ], \"quantify\" , \"quantify_by_ {} \" . format ( quantify_method )) # 4. transcript assembly transcript_assembly_method = 'stringtie' # star transcript_assembly_outdir = join ( config [ \"resultsDir\" ], \"transcript_assembly\" , \"transcript_assembly_by_ {} \" . format ( transcript_assembly_method )) # blast # 1. expression matrix database create exp_db_outdir = join ( config [ \"dbDir\" ], \"exp\" ) anno_db_outdir = join ( config [ \"dbDir\" ], \"anno\" ) # sqlite3 # 2. blastdb blastdb_outdir = join ( config [ \"dbDir\" ], \"blastdb\" ) # 3. gffutils gffdb_outdir = join ( config [ \"dbDir\" ], \"gff_sqlite3\" ) # 4. genomebrowse gbrowse_outdir = join ( config [ \"dbDir\" ], \"gbrowse\" ) annotation_gbrowse_outdir = join ( gbrowse_outdir , 'annotation' ) # include modules include : join ( \"rules\" , \"8.db_generate_of_exp.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_gff.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_blastdb.Snakefile.py\" ) include : join ( \"rules\" , \"8.db_generate_of_genomebrowser.Snakefile.py\" ) Then, run db_generate workflow to generate database files. snakemake -s ngspipe/db_generate.Snakefile.py --configfile ngspipe/config/ngsdb.config.yaml -p -j 1","title":"1. convert NGSPipe analysis results to sqlite3 format "},{"location":"NGSDb/#2-config","text":"edit mysite/mysite/settings.py file # Application definition INSTALLED_APPS = [ 'django.contrib.admin' , 'django.contrib.auth' , 'django.contrib.contenttypes' , 'django.contrib.sessions' , 'django.contrib.messages' , 'django.contrib.staticfiles' , # add custom app 'geneAnno' , # gene annotation from nr/nt/pfam/go/kegg 'geneExpAtlas' , # gene expression matrix 'blast' , # blast tool ]","title":"2. config "},{"location":"NGSDb/#3-start-server","text":"Starting server by run python ngsdb/manage.py runserver , visit sebsite on http://127.0.0.1:8000.","title":"3. start server "},{"location":"NGSDb/#4-add-your-custome-data","text":"Let's assume that you have the data you need to generate the database, such as gene annotation files, gene expression matrix and analysis reports. Before further steps, please install CONDA and download the latest source code of NGSPipeDb . Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb table data in a page custome script in wooey python manage.py makemigrations python manage.py migrate python manage.py addscript ../ngsdb/tools/test1.py If you want use wooey tools on a task model celery -A ProjectName worker -c 1 --beat -l info optional.","title":"4. add your custome data"},{"location":"NGSDb/#script","text":"\u56e0\u4e3a\u8fd0\u884cscript\u7684\u65f6\u5019\u662f\u4f7f\u7528\u7edd\u5bf9\u8def\u5f84\uff0c\u90a3\u4e48addscript\u7684\u65f6\u5019\u548c\u8fd0\u884cscript\u7684\u65f6\u5019\u6587\u4ef6\u8def\u5f84\u5fc5\u987b\u4e0d\u80fd\u53d8\u3002\u5982\u4f55\u53d8\u6210\u76f8\u5bf9\u8def\u5f84\u5462\uff1f\u53e6\u5916\u5728admin\u7ba1\u7406\u9875\u9762script\u4e5f\u4e0d\u80fd\u76f4\u63a5\u8bbf\u95ee\u7684\u3002","title":"\u6dfb\u52a0script"},{"location":"NGSDb/#5-overview-the-ngsdb-apps","text":"We use django project to constructed our NGSDb. We have pareparied many apps for you. embeed. Please have a look: django apps description package report ngs analysis report snakemake geneExpAtlas table datatable js network table datatable js igv genome browse IGV blastplus ncbi blast + NCBI ngstools python script wooey efp efp browse heatmap expression clustergrammer-js https://clustergrammer.readthedocs.io/clustergrammer_js.html","title":"5. overview the NGSDb apps"},{"location":"NGSPipe-ChIP-seq/","text":"\u4f7f\u7528\u6559\u7a0b conda create -n ngspipe_chipseq conda activate ngspipe_chipseq conda install mamba -c conda-forge mamba env update \u2013file ngspipe/envs/requirements_chipseq.yaml \u2013prune snakemake -s ngspipe/ChIP_seq.Snakefile.py \u2013configfile ngspipe/config/chipseq.config.yaml -np","title":"NGSPipe ChIP-seq"},{"location":"NGSPipe-ChIP-seq/#_1","text":"conda create -n ngspipe_chipseq conda activate ngspipe_chipseq conda install mamba -c conda-forge mamba env update \u2013file ngspipe/envs/requirements_chipseq.yaml \u2013prune snakemake -s ngspipe/ChIP_seq.Snakefile.py \u2013configfile ngspipe/config/chipseq.config.yaml -np","title":"\u4f7f\u7528\u6559\u7a0b"},{"location":"NGSPipe-RNA-seq/","text":"RNA-seq analysis Quick Start - One time installation of components necessary for RNA-Seq analysis Linux & WSL # download ngspipedb to anywhere you want git clone git://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_ranseq_test.sh MacOSX # download ngspipedb to anywhere you want git clone git://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_ranseq_test.sh Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . If you have more time, then we recommend you configure ngspipedb according to your needs. For more details, please see step by step bellow. Step-by-step RNA-seq workflow on testdata Although included in this section are step-by-step instructions, it is assumed that the user has a basic understanding of the nix command line interface . Also, best practice RNA-seq analysis is plus. Please find the easy learn matieral in linux & shell and RNASeq background . 1. Install wget and git To get some of the required software packages, we will use the command line tools called wget and git . wget is a popular tool for downloading things off of the internet. git is a distributed version control system which we will use to checkout the NGSPipeDb code. Note These tools are already pre-installed in most systems, but if you are unsure whether or not you have wget enter wget and if the return is wget: command not found , then you will have to install wget . Do likewise for git . 2. Install Miniconda3 NGSPipeDb relies on the conda package manager for installation and dependency resolution, so you will need to install conda first. We will be using the Miniconda3 package management system (aka CONDA ) to manage all of the software packages that NGSPipeDb is dependent on. Use following commands to retrieve and then run the Minicoda3 installation script: 1. wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. bash Miniconda3-latest-Linux-x86_64.sh . While running the installation script, follow the commands listed on screen, and press the enter key to scroll. Make sure to answer yes when asked if you want to prepend Miniconda3 to PATH. After that, close your terminal, open a new one and you should now have Conda working! You could, alternatively, run source ~/.bashrc to initiate conda. 3. Test by entering: conda update conda . Press y to confirm the conda updates. 4. conda install mamba -c conda-forge . Mamba is a reimplementation of the conda package manager in C++, the fast conda-alternative. Note You will only have to install Minicoda3 once. 3. Download NGSPipeDb source code To install the latest stable version of NGSPipeDb, please clone the git repository to your system. git method 1 cd /path/to/where_you_want git clone https://www.github.com/xuanblo/NGSPipeDb git method 2 cd /path/to/where_you_want git clone git://www.github.com/xuanblo/NGSPipeDb method 3: specific version If you want to use specific version, please cleckout the release and issue the following commands: cd /path/to/where_you_want wget https://github.com/xuanblo/NGSPipeDb/archive/NGSPipeDb_v0.0.1.tar.gz tar -xf NGSPipeDb_v0.0.1.tar.gz All of analysis will be performed under the source code directory directly. So you can change direcory name by: if you use git mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb if you use specific version mv NGSPipeDb-NGSPipeDb_v0.0.1 species_sample_transcript_analysis_by_NGSPipeDb Enter directory cd species_sample_transcript_analysis_by_NGSPipeDb for further setps. This will create the following structure: ./ \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata 4. Installing the NGSPipe RNA-Seq conda environments We are now ready to use conda to install the dependencies of which NGSPipe RNA-Seq analysis is required. First, you will need to create a conda environments. For details, see manage envirement with conda. Snakemake and Python is the basic tool of ngspipedb. mamba create -c conda-forge -c bioconda --name ngspipe-rnaseq snakemake = 5 .30.2 python = 3 .8 seqkit = 0 .14.0 Next, to analysis NGS data some bioinformatics tools need to be installed. mamba env update -n ngspipe-rnaseq --file ngspipe/envs/requirements_rnaseq.yaml --prune Activate conda environment: conda activate ngspipe-rnaseq If the conda downloading encounters any problems, you can refer to how to install pre-build ngspipe-ranseq env . Note By default, environments are installed into the envs directory in your conda directory ( ~/miniconda/conda/env/ngspipedb ). 5. Downloading the test files NGSPipe is dependent on reference files and raw sequence reads which can be found for the supported species listed below: download link To download the mouse RNA-seq test data into ./testdata : use script bash ngspipe/scripts/download_testdata.sh testdata use wget or download the test files (160M) that you need and then untarring then in a directory called testdata . wget http://www.liu-lab.com/ngspipedb/rnaseq_testdata.tar.gz tar -zxvf rnaseq_testdata.tar.gz Generate replicated samples: cd testdata python ../ngspipe/scripts/generate_replicat.py control_R1.fq.gz control_R2.fq.gz treated_R1.fq.gz treated_R2.fq.gz rm -f control_R1.fq.gz control_R2.fq.gz treated_R1.fq.gz treated_R2.fq.gz gunzip chr19.fa.gz gunzip GRCm38.83.chr19.gtf.gz cd .. Make sure you have the following directory structure by command tree testdata : testdata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u251c\u2500\u2500 chr19.fa \u251c\u2500\u2500 condition.xls \u251c\u2500\u2500 control-0_R1.fq.gz \u251c\u2500\u2500 control-0_R2.fq.gz \u251c\u2500\u2500 control-1_R1.fq.gz \u251c\u2500\u2500 control-1_R2.fq.gz \u251c\u2500\u2500 control-2_R1.fq.gz \u251c\u2500\u2500 control-2_R2.fq.gz \u251c\u2500\u2500 samples.xls \u251c\u2500\u2500 treated-0_R1.fq.gz \u251c\u2500\u2500 treated-0_R2.fq.gz \u251c\u2500\u2500 treated-1_R1.fq.gz \u251c\u2500\u2500 treated-1_R2.fq.gz \u251c\u2500\u2500 treated-2_R1.fq.gz \u2514\u2500\u2500 treated-2_R2.fq.gz Note This data is only used to test the analysis process, and the analysis results have no biological significance. 6. run RNA-seq analysis on test data We provied a simple RNA-seq workflow for you to take a glance of NGSPipe. In RNA-seq analysis part, it contains 7 step analysis: 1. sampling data 2. raw reads qc 3. junction alignmnet 4. transcript assembly 5. quantification 6. statistic 7. diff First, we need to check the ngspipe/file . This will not execute anything, but display what would be done. # dry run, use -n parameter only print task plan, -p print commands snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -np If nothing goes wrong, you can generate a dag plot: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml --dag | dot -Tpng > dag.png Now you can do RNA-seq analysis by just one simply command. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j 10 The final data files are put in the folder results . Please check you result file tree -d -L 2 results/ , it may like this: results/ \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 1.rawreads_stat \u2502 \u251c\u2500\u2500 2.cleanreads_stat \u2502 \u251c\u2500\u2500 3.mapping_stat \u2502 \u251c\u2500\u2500 4.exp_stat \u2502 \u2514\u2500\u2500 workflow \u2514\u2500\u2500 result \u251c\u2500\u2500 diff \u251c\u2500\u2500 junction_align \u251c\u2500\u2500 quantify \u251c\u2500\u2500 rawReads_qc \u251c\u2500\u2500 sampling_data \u251c\u2500\u2500 statistic \u2514\u2500\u2500 transcript_assembly Note If you encounter any problem in this step, please turn to TroubleShooting for help. 7. rgenerate report If all goes well, the proper analysis will be followed by the making of the html report using Snakemake to a html report file with pictures and tables. snakemake --snakefile ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml --report results/report/report.html The final report should appear as results/report/report.html . This report is a single html file with all in it and can be sent to customers/colleagues as a final report. It is nicer than a PDF version because of large tables and figures which would suffer from page breaks and it can be viewed on any device supporting html include smartphones :-). Note Internet Explorer is not supported. run your custome data NGSPipe is built to be used routinely. To ensure a maximum comparability of the results, you can copy default ngspipe/config/rnaseq.config.yaml and ngspipe/rnaseq_analysis.Snakefile.py file to the same directory: cp ngspipe/config/rnaseq.config.yaml ngspipe/config/my_own_rnaseq.config.yaml cp ngspipe/rnaseq_analysis.Snakefile.py ngspipe/my_own_rnaseq_analysis.Snakefile.py We will explain how to edit and configure these files shortly below. 1. Rawdata sequence data Raw data files can either be fastq, fastq.gz formated files. makedir rawdata and upload your own data to this directory. If your raw data are located in somewhere else , you can copy them to rawdata , or create soft links like ln -s ../yoursamplepath/*.fq.gz rawdata/ . rawdata/ \u251c\u2500\u2500 lung-rep1_R1.fq.gz \u251c\u2500\u2500 lung-rep1_R2.fq.gz \u251c\u2500\u2500 lung-rep2_R1.fq.gz \u251c\u2500\u2500 lung-rep2_R2.fq.gz \u251c\u2500\u2500 lung-rep3_R1.fq.gz \u251c\u2500\u2500 lung-rep3_R2.fq.gz \u251c\u2500\u2500 liver-rep1_R1.fq.gz \u251c\u2500\u2500 liver-rep1_R2.fq.gz \u251c\u2500\u2500 liver-rep2_R1.fq.gz \u251c\u2500\u2500 liver-rep2_R2.fq.gz \u251c\u2500\u2500 liver-rep3_R1.fq.gz \u251c\u2500\u2500 liver-rep3_R2.fq.gz As recommended above, if all of your raw data are located in rawdata , then create a rawdata/samples.xls file like: lung-rep1 lung-rep2 lung-rep3 liver-rep1 liver-rep2 liver-rep3 Note You cannot mix Paired-end and Single-end samples within the same NGSPipe run as this will cause an ERROR. NGSPipe only support Paired-end samples. 2. Reference data You can download reference data from NCBI, Ensembl, or anywhere else to genomedata . The most import file is genome in Fasta formant and gene annotation in GFF/GTF format. Use the same method as rawdata does: genomedata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u2514\u2500\u2500 chr19.fa 3. Edit config file In this section, you will need to specify every term to match your own machine, reference genome, and data. # path relative to where you run snakemake ## reference ## genomeAnno : \"testdata/GRCm38.83.chr19.gtf\" # gene annotation file, can be gtf or gff genomeFasta : \"testdata/chr19.fa\" # genome sequence ## output directory ## resultsDir : \"results/result\" reportsDir : \"results/report\" dbDir : \"results/sqlite3\" ## input ## samplesList : \"testdata/samples.xls\" # sample file samplesDir : \"testdata\" # sample file directory read1Suffix : \"_R1.fq.gz\" # fastq suffix, read1 read2Suffix : \"_R2.fq.gz\" replict_num : 3 # replict can by 1,2,3 # condition for differential expression by deseq2 Note The input, output file paths are relative to the working directory. 4. Condition for sample compare To perform gene differential analysis, please create a rawdata/condition.xls file. sample_id,Sample,Tissue lung-rep1,lung,normal lung-rep2,lung,normal lung-rep3,lung,normal liver-rep1,liver,tumor liver-rep2,liver,tumor liver-rep3,liver,tumor 5. edit snakefile Edit file ngspipe/workflow/rnaseq_analysis.Snakefile.py for advance setting, such as sampling data method, mapping tool, and email address to receive run log. # relative path snake_dir = workflow . basedir # all configfile, scripts, restructuretext, ens are relative to snakefile (this file) working_dir = os . getcwd () # input and output path are relative to current working directory # get notice receiver_email = 'youemailaddress' # ----------------------------------------------------------------------- # # sample information # # smpList = pd . read_csv ( config [ \"samplesList\" ], index_col = 0 , header = None ) SAMPLES = list ( smpList . index )[ 0 :] # how many sample you want to run. # ----------------------------------------------------------------------- # # -------------------------------------------------------------------------------------------------------------------------------------------------------------------- # # detail parameters in pipe # # # 1. sampling data # for test the pipe, you can choose to the part of the input file, can be whole,head:40000,tail:40000,random:0.5,random:40000 sampling_method = 'links' # tail, seqkit_number, seqkit_proportion, head, tail sampling_data_outdir = join ( config [ \"resultsDir\" ], \"sampling_data\" , \"sampling_data_by_ {} \" . format ( sampling_method )) # 2. raw reads qc qc_method = 'trim-galore' # trimomatic qc_outdir = join ( config [ \"resultsDir\" ], \"rawReads_qc\" , \"rawReads_qc_by_ {} \" . format ( qc_method )) # 3. junction alignmnet junction_align_method = 'hisat2' # star junction_align_outdir = join ( config [ \"resultsDir\" ], \"junction_align\" , \"junction_align_by_ {} \" . format ( junction_align_method )) genome_index_prefix = \"genome\" # rna-seq sequencing type, can be fr-firststrand, none, fr-secondstrand rna_library = \"\" # \"--rna-strandness RF\"(fr-firststrand) or \"--rna-strandness FR\"(fr-secondstrand) # 4. transcript assembly transcript_assembly_method = 'stringtie' # star transcript_assembly_outdir = join ( config [ \"resultsDir\" ], \"transcript_assembly\" , \"transcript_assembly_by_ {} \" . format ( transcript_assembly_method )) # 5. quantification quantify_method = 'stringtie' # htseqcounts or featurecounts quantify_outdir = join ( config [ \"resultsDir\" ], \"quantify\" , \"quantify_by_ {} \" . format ( quantify_method )) # 6. statistic statistic_data_all = [ '0.genomeFa' , '0.genomeAnno' , '1.rawReads' , '2.cleanReads' , '2.multiqc' , '3.bam' , '4.mergedGtf' , '5.exp' , ] genomeFa_outdir , genomeAnno_outdir , rawReads_outdir , cleanReads_outdir , multiqc_outdir , bam_outdir , mergedGtf_outdir , exp_outdir \\ = [ join ( config [ \"resultsDir\" ], \"statistic\" , \"statistic_data_of_ {} \" . format ( i )) for i in statistic_data_all ] statistic_data_choose = [ #'0.genomeFa', #'0.genomeAnno', '1.rawReads' , '2.cleanReads' , #'2.multiqc', '3.bam' , #'4.mergedGtf', #'5.exp', ] stat_outdir = join ( config [ \"resultsDir\" ], \"statistic\" ) # 7. diff gene discovery diff_outdir = join ( config [ \"resultsDir\" ], \"diff\" , \"diff_by_ {} \" . format ( 'deseq2' )) # -------------------------------------------------------------------------------------------------------------------------------------------------------------------- # # ------------------------------ #report: \"report/workflow.rst\" report_outdir = join ( config [ \"reportsDir\" ], \"report.html\" ) # ------------------------------ # include modules include : join ( \"rules\" , \"1.sampling_data_by_ {} .Snakefile.py\" . format ( sampling_method )) include : join ( \"rules\" , \"2.rawReads_qc_by_ {} .Snakefile.py\" . format ( qc_method )) include : join ( \"rules\" , \"3.junction_align_by_ {} .Snakefile.py\" . format ( junction_align_method )) include : join ( \"rules\" , \"4.transcript_assembly_by_ {} .Snakefile.py\" . format ( transcript_assembly_method )) include : join ( \"rules\" , \"5.quant_by_ {} .Snakefile.py\" . format ( quantify_method )) include : join ( \"rules\" , \"6.statistic_data_of_bam.Snakefile.py\" ) include : join ( \"rules\" , \"6.statistic_data_of_rawReads.Snakefile.py\" ) include : join ( \"rules\" , \"6.statistic_data_of_cleanReads.Snakefile.py\" ) include : join ( \"rules\" , \"7.report.Snakefile.py\" ) include : join ( \"rules\" , \"9.differential_expression.deseq2.Snakefile.py\" ) Note The script/env/include path is always relative to the Snakefile containing the directive (in contrast to the input, output and log file paths, which are relative to the working directory). 6. Custome report edit ngspipe/report/*.rst that will be added at the end of the report. For example, edit the ngspipe/report/rawreads_stat.rst file to include a text describing the 'Statistic' of the experiment. This text will be added to the report as static section and is one of the two report sections that can be edited by the end-user. summary of reads produced ======================== = The details of the data quality are as follows: # . Sample name : Sample name # . Raw reads : Count raw sequence data , with four rows in a unit , count the number of sequencing sequences in each file # . Clean reads : The calculation method is the same as that of Raw reads , except that the statistical files are filtered sequencing data , and subsequent bioinformatics analysis is based on Clean reads # . Clean bases : Multiply the number of sequencing sequences by the length of the sequencing sequence and convert it to G as the unit # . Error rate : base sequencing error rate # . Q20 , Q30 : respectively represent the percentage of bases whose Phred value is greater than 20 and 30 to the total bases # . GC content : the percentage of the total number of bases G and C to the total number of bases NGSPipe will provide you with an interactive, browser-based report, showing the most important measures of your data on the first sight. All tables in the report can be sorted and filtered. The table on the first tab shows the key values for a quick estimation of the success of your sequencing experiment and the assembly. On the second tab, there is a more detailed table, giving many additional measures. Additionally to the tables, many measures are provided as graphical feedback. On the third tab, you see plots which are generated for one complete sequencing experiment. On the fourth tab, there are plots which each show measures on one specific dataset. 7. Run snakemake Run snakemake in a prebuild environment: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> Or install dependencies while snakemake run. By default, all dependencies and tools should automatically be installed on the first execution. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> --use-conda See Specifying a location for an environment or run conda create \u2013help for information on specifying a different path. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> -p ./ngspipe_rnaseq_macox64","title":"NGSPipe RNA-seq"},{"location":"NGSPipe-RNA-seq/#rna-seq-analysis","text":"","title":"RNA-seq analysis"},{"location":"NGSPipe-RNA-seq/#quick-start-one-time-installation-of-components-necessary-for-rna-seq-analysis","text":"Linux & WSL # download ngspipedb to anywhere you want git clone git://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_ranseq_test.sh MacOSX # download ngspipedb to anywhere you want git clone git://github.com/xuanblo/NGSPipeDb.git && mv NGSPipeDb mouse_transcriptome_analysis && cd mouse_transcriptome_analysis # download test data and create environment bash ngspipe/scripts/one_step_ranseq_test.sh Now you can viste your website on http://127.0.0.1:8000. All result are stored in results . - Example of report . If you have more time, then we recommend you configure ngspipedb according to your needs. For more details, please see step by step bellow.","title":"Quick Start - One time installation of components necessary for RNA-Seq analysis "},{"location":"NGSPipe-RNA-seq/#step-by-step-rna-seq-workflow-on-testdata","text":"Although included in this section are step-by-step instructions, it is assumed that the user has a basic understanding of the nix command line interface . Also, best practice RNA-seq analysis is plus. Please find the easy learn matieral in linux & shell and RNASeq background .","title":"Step-by-step RNA-seq workflow on testdata "},{"location":"NGSPipe-RNA-seq/#1-install-wget-and-git","text":"To get some of the required software packages, we will use the command line tools called wget and git . wget is a popular tool for downloading things off of the internet. git is a distributed version control system which we will use to checkout the NGSPipeDb code. Note These tools are already pre-installed in most systems, but if you are unsure whether or not you have wget enter wget and if the return is wget: command not found , then you will have to install wget . Do likewise for git .","title":"1. Install wget and git "},{"location":"NGSPipe-RNA-seq/#2-install-miniconda3","text":"NGSPipeDb relies on the conda package manager for installation and dependency resolution, so you will need to install conda first. We will be using the Miniconda3 package management system (aka CONDA ) to manage all of the software packages that NGSPipeDb is dependent on. Use following commands to retrieve and then run the Minicoda3 installation script: 1. wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh 2. bash Miniconda3-latest-Linux-x86_64.sh . While running the installation script, follow the commands listed on screen, and press the enter key to scroll. Make sure to answer yes when asked if you want to prepend Miniconda3 to PATH. After that, close your terminal, open a new one and you should now have Conda working! You could, alternatively, run source ~/.bashrc to initiate conda. 3. Test by entering: conda update conda . Press y to confirm the conda updates. 4. conda install mamba -c conda-forge . Mamba is a reimplementation of the conda package manager in C++, the fast conda-alternative. Note You will only have to install Minicoda3 once.","title":"2. Install Miniconda3 "},{"location":"NGSPipe-RNA-seq/#3-download-ngspipedb-source-code","text":"To install the latest stable version of NGSPipeDb, please clone the git repository to your system. git method 1 cd /path/to/where_you_want git clone https://www.github.com/xuanblo/NGSPipeDb git method 2 cd /path/to/where_you_want git clone git://www.github.com/xuanblo/NGSPipeDb method 3: specific version If you want to use specific version, please cleckout the release and issue the following commands: cd /path/to/where_you_want wget https://github.com/xuanblo/NGSPipeDb/archive/NGSPipeDb_v0.0.1.tar.gz tar -xf NGSPipeDb_v0.0.1.tar.gz All of analysis will be performed under the source code directory directly. So you can change direcory name by: if you use git mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb if you use specific version mv NGSPipeDb-NGSPipeDb_v0.0.1 species_sample_transcript_analysis_by_NGSPipeDb Enter directory cd species_sample_transcript_analysis_by_NGSPipeDb for further setps. This will create the following structure: ./ \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata","title":"3. Download NGSPipeDb source code "},{"location":"NGSPipe-RNA-seq/#4-installing-the-ngspipe-rna-seq-conda-environments","text":"We are now ready to use conda to install the dependencies of which NGSPipe RNA-Seq analysis is required. First, you will need to create a conda environments. For details, see manage envirement with conda. Snakemake and Python is the basic tool of ngspipedb. mamba create -c conda-forge -c bioconda --name ngspipe-rnaseq snakemake = 5 .30.2 python = 3 .8 seqkit = 0 .14.0 Next, to analysis NGS data some bioinformatics tools need to be installed. mamba env update -n ngspipe-rnaseq --file ngspipe/envs/requirements_rnaseq.yaml --prune Activate conda environment: conda activate ngspipe-rnaseq If the conda downloading encounters any problems, you can refer to how to install pre-build ngspipe-ranseq env . Note By default, environments are installed into the envs directory in your conda directory ( ~/miniconda/conda/env/ngspipedb ).","title":"4. Installing the NGSPipe RNA-Seq conda environments "},{"location":"NGSPipe-RNA-seq/#5-downloading-the-test-files","text":"NGSPipe is dependent on reference files and raw sequence reads which can be found for the supported species listed below: download link To download the mouse RNA-seq test data into ./testdata : use script bash ngspipe/scripts/download_testdata.sh testdata use wget or download the test files (160M) that you need and then untarring then in a directory called testdata . wget http://www.liu-lab.com/ngspipedb/rnaseq_testdata.tar.gz tar -zxvf rnaseq_testdata.tar.gz Generate replicated samples: cd testdata python ../ngspipe/scripts/generate_replicat.py control_R1.fq.gz control_R2.fq.gz treated_R1.fq.gz treated_R2.fq.gz rm -f control_R1.fq.gz control_R2.fq.gz treated_R1.fq.gz treated_R2.fq.gz gunzip chr19.fa.gz gunzip GRCm38.83.chr19.gtf.gz cd .. Make sure you have the following directory structure by command tree testdata : testdata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u251c\u2500\u2500 chr19.fa \u251c\u2500\u2500 condition.xls \u251c\u2500\u2500 control-0_R1.fq.gz \u251c\u2500\u2500 control-0_R2.fq.gz \u251c\u2500\u2500 control-1_R1.fq.gz \u251c\u2500\u2500 control-1_R2.fq.gz \u251c\u2500\u2500 control-2_R1.fq.gz \u251c\u2500\u2500 control-2_R2.fq.gz \u251c\u2500\u2500 samples.xls \u251c\u2500\u2500 treated-0_R1.fq.gz \u251c\u2500\u2500 treated-0_R2.fq.gz \u251c\u2500\u2500 treated-1_R1.fq.gz \u251c\u2500\u2500 treated-1_R2.fq.gz \u251c\u2500\u2500 treated-2_R1.fq.gz \u2514\u2500\u2500 treated-2_R2.fq.gz Note This data is only used to test the analysis process, and the analysis results have no biological significance.","title":"5. Downloading the test files "},{"location":"NGSPipe-RNA-seq/#6-run-rna-seq-analysis-on-test-data","text":"We provied a simple RNA-seq workflow for you to take a glance of NGSPipe. In RNA-seq analysis part, it contains 7 step analysis: 1. sampling data 2. raw reads qc 3. junction alignmnet 4. transcript assembly 5. quantification 6. statistic 7. diff First, we need to check the ngspipe/file . This will not execute anything, but display what would be done. # dry run, use -n parameter only print task plan, -p print commands snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -np If nothing goes wrong, you can generate a dag plot: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml --dag | dot -Tpng > dag.png Now you can do RNA-seq analysis by just one simply command. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j 10 The final data files are put in the folder results . Please check you result file tree -d -L 2 results/ , it may like this: results/ \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 1.rawreads_stat \u2502 \u251c\u2500\u2500 2.cleanreads_stat \u2502 \u251c\u2500\u2500 3.mapping_stat \u2502 \u251c\u2500\u2500 4.exp_stat \u2502 \u2514\u2500\u2500 workflow \u2514\u2500\u2500 result \u251c\u2500\u2500 diff \u251c\u2500\u2500 junction_align \u251c\u2500\u2500 quantify \u251c\u2500\u2500 rawReads_qc \u251c\u2500\u2500 sampling_data \u251c\u2500\u2500 statistic \u2514\u2500\u2500 transcript_assembly Note If you encounter any problem in this step, please turn to TroubleShooting for help.","title":"6. run RNA-seq analysis on test data "},{"location":"NGSPipe-RNA-seq/#7-rgenerate-report","text":"If all goes well, the proper analysis will be followed by the making of the html report using Snakemake to a html report file with pictures and tables. snakemake --snakefile ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml --report results/report/report.html The final report should appear as results/report/report.html . This report is a single html file with all in it and can be sent to customers/colleagues as a final report. It is nicer than a PDF version because of large tables and figures which would suffer from page breaks and it can be viewed on any device supporting html include smartphones :-). Note Internet Explorer is not supported.","title":"7. rgenerate report "},{"location":"NGSPipe-RNA-seq/#run-your-custome-data","text":"NGSPipe is built to be used routinely. To ensure a maximum comparability of the results, you can copy default ngspipe/config/rnaseq.config.yaml and ngspipe/rnaseq_analysis.Snakefile.py file to the same directory: cp ngspipe/config/rnaseq.config.yaml ngspipe/config/my_own_rnaseq.config.yaml cp ngspipe/rnaseq_analysis.Snakefile.py ngspipe/my_own_rnaseq_analysis.Snakefile.py We will explain how to edit and configure these files shortly below.","title":"run your custome data "},{"location":"NGSPipe-RNA-seq/#1-rawdata-sequence-data","text":"Raw data files can either be fastq, fastq.gz formated files. makedir rawdata and upload your own data to this directory. If your raw data are located in somewhere else , you can copy them to rawdata , or create soft links like ln -s ../yoursamplepath/*.fq.gz rawdata/ . rawdata/ \u251c\u2500\u2500 lung-rep1_R1.fq.gz \u251c\u2500\u2500 lung-rep1_R2.fq.gz \u251c\u2500\u2500 lung-rep2_R1.fq.gz \u251c\u2500\u2500 lung-rep2_R2.fq.gz \u251c\u2500\u2500 lung-rep3_R1.fq.gz \u251c\u2500\u2500 lung-rep3_R2.fq.gz \u251c\u2500\u2500 liver-rep1_R1.fq.gz \u251c\u2500\u2500 liver-rep1_R2.fq.gz \u251c\u2500\u2500 liver-rep2_R1.fq.gz \u251c\u2500\u2500 liver-rep2_R2.fq.gz \u251c\u2500\u2500 liver-rep3_R1.fq.gz \u251c\u2500\u2500 liver-rep3_R2.fq.gz As recommended above, if all of your raw data are located in rawdata , then create a rawdata/samples.xls file like: lung-rep1 lung-rep2 lung-rep3 liver-rep1 liver-rep2 liver-rep3 Note You cannot mix Paired-end and Single-end samples within the same NGSPipe run as this will cause an ERROR. NGSPipe only support Paired-end samples.","title":"1. Rawdata sequence data "},{"location":"NGSPipe-RNA-seq/#2-reference-data","text":"You can download reference data from NCBI, Ensembl, or anywhere else to genomedata . The most import file is genome in Fasta formant and gene annotation in GFF/GTF format. Use the same method as rawdata does: genomedata/ \u251c\u2500\u2500 GRCm38.83.chr19.gtf \u2514\u2500\u2500 chr19.fa","title":"2. Reference data "},{"location":"NGSPipe-RNA-seq/#3-edit-config-file","text":"In this section, you will need to specify every term to match your own machine, reference genome, and data. # path relative to where you run snakemake ## reference ## genomeAnno : \"testdata/GRCm38.83.chr19.gtf\" # gene annotation file, can be gtf or gff genomeFasta : \"testdata/chr19.fa\" # genome sequence ## output directory ## resultsDir : \"results/result\" reportsDir : \"results/report\" dbDir : \"results/sqlite3\" ## input ## samplesList : \"testdata/samples.xls\" # sample file samplesDir : \"testdata\" # sample file directory read1Suffix : \"_R1.fq.gz\" # fastq suffix, read1 read2Suffix : \"_R2.fq.gz\" replict_num : 3 # replict can by 1,2,3 # condition for differential expression by deseq2 Note The input, output file paths are relative to the working directory.","title":"3. Edit config file "},{"location":"NGSPipe-RNA-seq/#4-condition-for-sample-compare","text":"To perform gene differential analysis, please create a rawdata/condition.xls file. sample_id,Sample,Tissue lung-rep1,lung,normal lung-rep2,lung,normal lung-rep3,lung,normal liver-rep1,liver,tumor liver-rep2,liver,tumor liver-rep3,liver,tumor","title":"4. Condition for sample compare "},{"location":"NGSPipe-RNA-seq/#5-edit-snakefile","text":"Edit file ngspipe/workflow/rnaseq_analysis.Snakefile.py for advance setting, such as sampling data method, mapping tool, and email address to receive run log. # relative path snake_dir = workflow . basedir # all configfile, scripts, restructuretext, ens are relative to snakefile (this file) working_dir = os . getcwd () # input and output path are relative to current working directory # get notice receiver_email = 'youemailaddress' # ----------------------------------------------------------------------- # # sample information # # smpList = pd . read_csv ( config [ \"samplesList\" ], index_col = 0 , header = None ) SAMPLES = list ( smpList . index )[ 0 :] # how many sample you want to run. # ----------------------------------------------------------------------- # # -------------------------------------------------------------------------------------------------------------------------------------------------------------------- # # detail parameters in pipe # # # 1. sampling data # for test the pipe, you can choose to the part of the input file, can be whole,head:40000,tail:40000,random:0.5,random:40000 sampling_method = 'links' # tail, seqkit_number, seqkit_proportion, head, tail sampling_data_outdir = join ( config [ \"resultsDir\" ], \"sampling_data\" , \"sampling_data_by_ {} \" . format ( sampling_method )) # 2. raw reads qc qc_method = 'trim-galore' # trimomatic qc_outdir = join ( config [ \"resultsDir\" ], \"rawReads_qc\" , \"rawReads_qc_by_ {} \" . format ( qc_method )) # 3. junction alignmnet junction_align_method = 'hisat2' # star junction_align_outdir = join ( config [ \"resultsDir\" ], \"junction_align\" , \"junction_align_by_ {} \" . format ( junction_align_method )) genome_index_prefix = \"genome\" # rna-seq sequencing type, can be fr-firststrand, none, fr-secondstrand rna_library = \"\" # \"--rna-strandness RF\"(fr-firststrand) or \"--rna-strandness FR\"(fr-secondstrand) # 4. transcript assembly transcript_assembly_method = 'stringtie' # star transcript_assembly_outdir = join ( config [ \"resultsDir\" ], \"transcript_assembly\" , \"transcript_assembly_by_ {} \" . format ( transcript_assembly_method )) # 5. quantification quantify_method = 'stringtie' # htseqcounts or featurecounts quantify_outdir = join ( config [ \"resultsDir\" ], \"quantify\" , \"quantify_by_ {} \" . format ( quantify_method )) # 6. statistic statistic_data_all = [ '0.genomeFa' , '0.genomeAnno' , '1.rawReads' , '2.cleanReads' , '2.multiqc' , '3.bam' , '4.mergedGtf' , '5.exp' , ] genomeFa_outdir , genomeAnno_outdir , rawReads_outdir , cleanReads_outdir , multiqc_outdir , bam_outdir , mergedGtf_outdir , exp_outdir \\ = [ join ( config [ \"resultsDir\" ], \"statistic\" , \"statistic_data_of_ {} \" . format ( i )) for i in statistic_data_all ] statistic_data_choose = [ #'0.genomeFa', #'0.genomeAnno', '1.rawReads' , '2.cleanReads' , #'2.multiqc', '3.bam' , #'4.mergedGtf', #'5.exp', ] stat_outdir = join ( config [ \"resultsDir\" ], \"statistic\" ) # 7. diff gene discovery diff_outdir = join ( config [ \"resultsDir\" ], \"diff\" , \"diff_by_ {} \" . format ( 'deseq2' )) # -------------------------------------------------------------------------------------------------------------------------------------------------------------------- # # ------------------------------ #report: \"report/workflow.rst\" report_outdir = join ( config [ \"reportsDir\" ], \"report.html\" ) # ------------------------------ # include modules include : join ( \"rules\" , \"1.sampling_data_by_ {} .Snakefile.py\" . format ( sampling_method )) include : join ( \"rules\" , \"2.rawReads_qc_by_ {} .Snakefile.py\" . format ( qc_method )) include : join ( \"rules\" , \"3.junction_align_by_ {} .Snakefile.py\" . format ( junction_align_method )) include : join ( \"rules\" , \"4.transcript_assembly_by_ {} .Snakefile.py\" . format ( transcript_assembly_method )) include : join ( \"rules\" , \"5.quant_by_ {} .Snakefile.py\" . format ( quantify_method )) include : join ( \"rules\" , \"6.statistic_data_of_bam.Snakefile.py\" ) include : join ( \"rules\" , \"6.statistic_data_of_rawReads.Snakefile.py\" ) include : join ( \"rules\" , \"6.statistic_data_of_cleanReads.Snakefile.py\" ) include : join ( \"rules\" , \"7.report.Snakefile.py\" ) include : join ( \"rules\" , \"9.differential_expression.deseq2.Snakefile.py\" ) Note The script/env/include path is always relative to the Snakefile containing the directive (in contrast to the input, output and log file paths, which are relative to the working directory).","title":"5. edit snakefile "},{"location":"NGSPipe-RNA-seq/#6-custome-report","text":"edit ngspipe/report/*.rst that will be added at the end of the report. For example, edit the ngspipe/report/rawreads_stat.rst file to include a text describing the 'Statistic' of the experiment. This text will be added to the report as static section and is one of the two report sections that can be edited by the end-user. summary of reads produced ======================== = The details of the data quality are as follows: # . Sample name : Sample name # . Raw reads : Count raw sequence data , with four rows in a unit , count the number of sequencing sequences in each file # . Clean reads : The calculation method is the same as that of Raw reads , except that the statistical files are filtered sequencing data , and subsequent bioinformatics analysis is based on Clean reads # . Clean bases : Multiply the number of sequencing sequences by the length of the sequencing sequence and convert it to G as the unit # . Error rate : base sequencing error rate # . Q20 , Q30 : respectively represent the percentage of bases whose Phred value is greater than 20 and 30 to the total bases # . GC content : the percentage of the total number of bases G and C to the total number of bases NGSPipe will provide you with an interactive, browser-based report, showing the most important measures of your data on the first sight. All tables in the report can be sorted and filtered. The table on the first tab shows the key values for a quick estimation of the success of your sequencing experiment and the assembly. On the second tab, there is a more detailed table, giving many additional measures. Additionally to the tables, many measures are provided as graphical feedback. On the third tab, you see plots which are generated for one complete sequencing experiment. On the fourth tab, there are plots which each show measures on one specific dataset.","title":"6. Custome report "},{"location":"NGSPipe-RNA-seq/#7-run-snakemake","text":"Run snakemake in a prebuild environment: snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> Or install dependencies while snakemake run. By default, all dependencies and tools should automatically be installed on the first execution. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> --use-conda See Specifying a location for an environment or run conda create \u2013help for information on specifying a different path. snakemake -s ngspipe/rnaseq_analysis.Snakefile.py --configfile ngspipe/config/rnaseq.config.yaml -p -j <thread number> -p ./ngspipe_rnaseq_macox64","title":"7. Run snakemake "},{"location":"NGSPipe-resequecing/","text":"resequcing analysis step-by-step run resequencing on testdata 1. pre-prepare download source code Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb 2. create conda envirenment mamba create -n ngspipe-resequencing python = 3 .8 -c conda-forge -y mamba env update -n ngspipe-resequencing --file ngspipe/envs/requirements_resequencing.yaml --prune conda activate ngspipe-resequecing - snpeff - gatk 3. download testdata mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/control_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/control_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/GRCm38.83.chr19.gtf.gz gunzip chr19.fa.gz gunzip GRCm38.83.chr19.gtf.gz wget http://www.liu-lab.com/ngspipedb/testdata/sample_resequecing.xls cd .. 4. run snakemake snakemake -s ngspipe/2.resequencing_analysis.Snakefile.py --configfile ngspipe/config/resequencing.config.yaml -p -j 1","title":"NGSPipe resequecing"},{"location":"NGSPipe-resequecing/#resequcing-analysis","text":"","title":"resequcing analysis"},{"location":"NGSPipe-resequecing/#step-by-step-run-resequencing-on-testdata","text":"","title":"step-by-step run resequencing on testdata"},{"location":"NGSPipe-resequecing/#1-pre-prepare-download-source-code","text":"Install wget and git Install Miniconda3 Download NGSPipeDb source code Modify the project name and enter the project directory. mv NGSPipeDb species_sample_transcript_analysis_by_NGSPipeDb cd species_sample_transcript_analysis_by_NGSPipeDb","title":"1. pre-prepare download source code"},{"location":"NGSPipe-resequecing/#2-create-conda-envirenment","text":"mamba create -n ngspipe-resequencing python = 3 .8 -c conda-forge -y mamba env update -n ngspipe-resequencing --file ngspipe/envs/requirements_resequencing.yaml --prune conda activate ngspipe-resequecing - snpeff - gatk","title":"2. create conda envirenment"},{"location":"NGSPipe-resequecing/#3-download-testdata","text":"mkdir -p testdata && cd testdata wget http://www.liu-lab.com/ngspipedb/testdata/control_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R1.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/control_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/treated_R2.fq.gz wget http://www.liu-lab.com/ngspipedb/testdata/chr19.fa.gz wget http://www.liu-lab.com/ngspipedb/testdata/GRCm38.83.chr19.gtf.gz gunzip chr19.fa.gz gunzip GRCm38.83.chr19.gtf.gz wget http://www.liu-lab.com/ngspipedb/testdata/sample_resequecing.xls cd ..","title":"3. download testdata"},{"location":"NGSPipe-resequecing/#4-run-snakemake","text":"snakemake -s ngspipe/2.resequencing_analysis.Snakefile.py --configfile ngspipe/config/resequencing.config.yaml -p -j 1","title":"4. run snakemake"},{"location":"NGSPipeDb/","text":"NGSPipeDb - NGS pipeline and database Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility Troubleshooting Introduction to NGSPipeDb NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser System requirements Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores. Anatomy of a NGSPipeDb project It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb. Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env \u2013clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528\u2013use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528\u2013use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config \u2013set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update \u2013prefix ./ngspipedb_py38_conda_env/ \u2013file requirement.yaml \u2013prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html \u2013conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba \u2013conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 \u2013conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py \u2013use-conda \u2013conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the \u2013use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use \u2013use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django Troubleshooting Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3 Contributing Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn )","title":"NGSPipeDb Tutorial"},{"location":"NGSPipeDb/#ngspipedb-ngs-pipeline-and-database","text":"Author: Dr. Xuan Zhang Last update: 2021-01-20 Citation: NGSPipeDb: An automated pipeline for parallel processing of huge NGS data and database generation. Table of Contents: Introduction to NGSPipeDb System requirements Anatomy of a NGSPipeDb project Basics: An example execution of RNA-seq analysis with test data Advance: An example execution of RNA-seq analysis with custome data Reproducibility Troubleshooting","title":"NGSPipeDb - NGS pipeline and database"},{"location":"NGSPipeDb/#introduction-to-ngspipedb","text":"NGSPipeDb is an automated pipeline for parallel processing of huge next generation sequencing (NGS) data and database generation using snakemake workflow which allows for ease of use, optimal speed, and a highly modular code that can be further added onto and customized by experienced users. It can be further divided into NGSPipe and NGSDb for individual usage. NGSPipe consists of a Snakefile ( ngspipe/rnaseq.snakefile.py , it includes some basic rules ngspipe/rule/*.snakefile.py ), conda environment files ( ngspipe/envs/*.yaml ), a configuration file ( ngspipe/config/rnaseq.config.yaml ), a set of python , R , Shell and Perl scripts ( ngspipe/scripts/*.py ), and a set of reStructuretext reports ( reports/*.rst ). It combines the use of several dozen omic-seq tools, suites, and packages to create a complete pipeline that takes RNA-seq analysis , resequcing analysis etc. from raw sequencing data all the way through alignment, quality control, unsupervised analyses, differential expression, and downstream pathway analysis. It is implemented such that alternative or similar analysis can be added or removed. The results are compiled in a simple and highly visual report containing the key figures to explain the analysis, and then compiles all of the relevant files, tables, and pictures into an easy to navigate folder. Table file such as csv, tsv, xlsx etc. It is based on snakemake and includes the following tools: * shovill (based on Spades) * QUAST v.5 (including BUSCO) * mash * fastp It will read untrimmed raw data from your illumina sequencing experiments as paired .fastq.gz-files. These are then trimmed, assembled and polished. Besides generating ready-for-use contigs, AQUAMIS will select the closest reference genome from NCBI RefSeq and produce an intuitive, detailed report on your data and assemblies to evaluate its reliability for further analyses. It relies on reference-based and reference-free measures such as coverage depth, gene content, genome completeness and contamination, assembly length and many more. Based on the experience from thousands of sequencing experiments, threshold sets for different species have been defined to detect potentially poor results. In addition, NGSDb has been outfitted with several recently published tools that allow for visualize and data share.can be convert to Sqlite3 format. The Django project and apps can be orgined by user defined. It is easy to share your data with a web inteface. a set of apps (such as home , igv , geneExpAtlas , efp brwose ). By default, the NGSPipeDb performs all the steps shown in the diagram below. However, advanced user, you can easily modify the Snakefile and the config.yaml and/or add \"custom rules\" to enable additional functions. Currently, transcript quantification with Salmon at the read-level or gene quantification by featureCounts can be activated. The first version handles RNA-Seq workflow. Workflows available: - RNA-seq - ChIP-seq - Resequencing TODO : NGSPipe miRNA scRNA-seq ATAC-seq NGSdb efp browser","title":"Introduction to NGSPipeDb "},{"location":"NGSPipeDb/#system-requirements","text":"Building NGSPipeDb and running the examples require Linux, MacOS or Windows Subsystem for Linux ( WSL ) on Win10. Other Unix environments will probably work but have not been tested. The test data can be run on personal computer, for example 8G memeory. Some of the tools that NGSPipeDb uses, e.g. STAR and cufflinks are very memory intensive programs. Therefore we recommend the following system requirements for NGSPipeDb: We recommend that you run NGSPipeDb on a server that has at least 30GB of ram. This will allow for a single-threaded NGSPipeDb run (on mouse samples). We recommend that you have at least 128GB of ram and at least a 4-core CPU if you want to run NGSPipeDb in multi-threaded mode (which will speedup the workflow significantly). Our own servers have 256GB of ram and 32 cores.","title":"System requirements "},{"location":"NGSPipeDb/#anatomy-of-a-ngspipedb-project","text":"It is recommended to download NGSPipeDb source and change its name to your project name (For example: mv NGSPipeDb mouse_transcriptome_analysis ), it may looks like the following structure (command: tree -d -L 2 mouse_transcriptome_analysis ): mouse_transcriptome_analysis \u251c\u2500\u2500 README.md \u251c\u2500\u2500 ngsdb \u2502 \u251c\u2500\u2500 blastplus \u2502 \u251c\u2500\u2500 db.sqlite3 \u2502 \u251c\u2500\u2500 geneAnno \u2502 \u251c\u2500\u2500 geneExpAtlas \u2502 \u251c\u2500\u2500 home \u2502 \u251c\u2500\u2500 igv \u2502 \u251c\u2500\u2500 manage.py \u2502 \u2514\u2500\u2500 ngsdb \u251c\u2500\u2500 ngspipe \u2502 \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 db_generate.Snakefile.py \u2502 \u251c\u2500\u2500 envs \u2502 \u251c\u2500\u2500 imgs \u2502 \u251c\u2500\u2500 notebooks \u2502 \u251c\u2500\u2500 reports \u2502 \u251c\u2500\u2500 rnaseq_analysis.Snakefile.py \u2502 \u251c\u2500\u2500 rules \u2502 \u2514\u2500\u2500 scripts \u251c\u2500\u2500 results \u2502 \u251c\u2500\u2500 report \u2502 \u251c\u2500\u2500 resultdata \u2502 \u2514\u2500\u2500 sqlite3 \u2514\u2500\u2500 testdata The workflow code goes into a subfolder ngspipe , while the configuration is stored in a subfolder config . Inside of the workflow subfolder, the central Snakefile marks the entrypoint of the workflow. In addition to the central Snakefile, rules are stored in a modular way, using the optional subfolder ngspipe/rules . Further, scripts are stored in a subfolder workflow/scripts and notebooks in a subfolder workflow/notebooks . Conda environments are stored in a subfolder workflow/envs . Finally, report caption files are stored in workflow/report . The database code goes into a subfolder ngsdb , while the manage.py is ngsdb's command-line utility for administrative tasks. A golabl setting file is stored under ngsdb/ngsdb , such as ngsdb/ngsdb/setting.py and ngsdb/ngsdb/urls.py . Many ngsdb function module take a app name. For example, if your INSTALLED_APPS in ngsdb/ngsdb/setting.py contains the string 'igv', the database will contain a page of IGV genome browser. All output files generated in the workflow should be stored under results/result , unless they are rather retrieved report, in which case they should be stored under results/report . The latter subfolder results/sqlite3 contains Sqlite3 kind file that shall be used by ngsdb.","title":"Anatomy of a NGSPipeDb project "},{"location":"NGSPipeDb/#basics-an-example-execution-of-rna-seq-analysis-with-test-data","text":"","title":"Basics: An example execution of RNA-seq analysis with test data"},{"location":"NGSPipeDb/#advance-an-example-execution-of-rna-seq-analysis-with-custome-data","text":"","title":"Advance: An example execution of RNA-seq analysis with custome data"},{"location":"NGSPipeDb/#reproducibility","text":"conda\u73af\u5883\u514b\u9686conda create -n ngspipedb_py38_conda_env \u2013clone ./ngspipedb_py38_conda_env/ use conda env export cd NGSPipeDB_source_code # export to yaml conda env export --no-builds -p ./ngspipedb_py38_conda_env >ngspipedb_py38_conda_env.yaml use conda pack \u7528\u2013use-conda\u8fd9\u4e2a\u53c2\u6570\u7684\u8bdd\uff0c\u56e0\u4e3a\u6240\u6709\u8f6f\u4ef6\u7684\u73af\u5883\u90fd\u662f\u5355\u72ec\u7684\uff0c\u6240\u6709conda\u5b89\u88c5\u7684\u65f6\u5019\u4e0d\u4f1a\u51fa\u9519\uff0c\u90a3\u4e48\u5982\u679c\u5df2\u7ecf\u4e0b\u8f7d\u5b89\u88c5\u597d\u4e86\u73af\u5883\uff0c\u7528\u8fd9\u79cd\u65b9\u5f0f\u5982\u4f55\u4f7f\u7528\uff1f\u9ed8\u8ba4\u7684\u73af\u5883\u662f.snakemake\u6587\u4ef6\u5939\u4e0b\uff0c\u5982\u4f55\u6307\u5b9a\uff1f \u7528\u4e0a\u9762\u7684\u65b9\u5f0f\u597d\u5b89\u88c5\uff0c\u4e0d\u4f1a\u51fa\u9519\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u6587\u4ef6\u5f88\u5927\uff0c\u591a\u5927\uff1f \u662f\u5426\u80fd\u628a\u4e00\u73af\u5883\u5206\u6210\u4e24\u90e8\u5206\uff1f\u4e00\u90e8\u5206\u8f6f\u4ef6\u96c6\u5408\u8d77\u6765\u53d8\u6210\u4e00\u4e2a\u5927\u73af\u5883\uff0c\u53e6\u4e00\u90e8\u5206\u8f6f\u4ef6\u5c31\u7528\u2013use-conda\u73af\u5883\u5355\u72ec\u6307\u5b9a\uff0c\u4f46\u662f\u8fd9\u4e24\u79cd\u65b9\u5f0f\u80fd\u7ed3\u5408\u5230\u4e00\u8d77\u7528\u5417\uff1f # pack cd NGSPipeDB_source_code mamba install -c conda-forge conda-pack conda pack -p ./ngspipedb_py38_conda_env -o ngspipedb_py38_conda_env_osx64.tar.gz # unpack on another machine mkdir -p ngspipedb_py38_conda_env tar -xzf ngspipedb_py38_conda_env_osx64.tar.gz -C ngspipedb_py38_conda_env source activate ./ngspipedb_py38_conda_env conda-unpack conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ conda config \u2013add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ activate base and set miniconda path conda init Conda Prompt Customization conda config \u2013set env_prompt '({name}) ' source ~/.bashrc update conda, (optional) conda update conda create conda visual environment, python version, snakemake version, env directory,django version conda create -p ngspipedb_py38_conda_env python=3.8 activate conda env conda activate ./ngspipedb_py38_conda_env install mamba to make install software faster. conda install mamba -c conda-forge update some bioinformatics tools we will use bellow. mamba env update \u2013prefix ./ngspipedb_py38_conda_env/ \u2013file requirement.yaml \u2013prune you can exit virtual environment by conda deactivate https://wooey.readthedocs.io/en/latest/install.html \u2013conda-frontend mamba \u9009\u62e9\u66f4\u5feb\u4e00\u70b9\u7684mamba \u2013conda-create-envs-only \u53ea\u521b\u5efa\u73af\u5883\uff0c\u7136\u540e\u9000\u51fa\uff0c\u4e0d\u8fd0\u884c\u7a0b\u5e8f\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u7528\u6765\u4e13\u95e8\u6d4b\u8bd5\u73af\u5883 mac\u4e0a\u7684conda\u73af\u5883\u597d\u50cf\u6ca1\u6709linux\u4e0a\u9762\u90a3\u4e48\u597d\u7528\uff0c\u7279\u522b\u662fanaconda\u521b\u5efa\u7684\u73af\u5883 \u2013conda-prefix \u6307\u5b9aconda\u73af\u5883\u5b89\u88c5\u5730\u5740 \u6e05\u7406conda\u5b89\u88c5\u5305\u548c\u7f13\u5b58 snakemake -s ngspipe/db_generate.Snakefile.py \u2013use-conda \u2013conda-prefix condaEnvSplit -p -j1 Simplest is just abandon the \u2013use-conda flag, as suggested in the answer. Alternatively, you could make a container that has the env pre-created and configured, then use \u2013use-singularity. Or, if the post-installation can be automated, one could build a custom Conda package that runs some post-linking scripts. Sorry I seem to have missed your comment! snakemake \u5982\u4f55\u8fd0\u884c\u5355\u4e2a\u7a0b\u5e8f\uff1f\u8fd9\u4e2a\u4e5f\u5f88\u6709\u7528 \u57fa\u56e0\u7684\u547d\u4ee4\uff0c\u50cfdkango\u8fd9\u6837\u7684\u547d\u4ee4\u5728\u5f88\u591arules\u4e2d\u90fd\u6709\uff0c\u6240\u6709\u6bd4\u5982\u6709\u4e2a\u9876\u5c42\u7684\u73af\u5883\u4e2d\u5b89\u88c5\u4e86django","title":"Reproducibility "},{"location":"NGSPipeDb/#troubleshooting","text":"Ngsdb.yaml+wooey Python=3.8 samtools clustergrammer Pip install wooey pip install pandas==0.25.3","title":"Troubleshooting "},{"location":"NGSPipeDb/#contributing","text":"Please submit an issue to report bugs or ask questions. Please contribute bug fixes or new features with a pull request to this repository. If this does not help, please feel free to consult: * Xuan Zhang ( zhangxuan@xtbg.ac.cn ) or * Changning Liu ( liuchangning@xtbg.ac.cn )","title":"Contributing"},{"location":"linux/","text":"Shell and Linux Author: Hanrui Bai, 2021-2-15 About Linux The complete Linux operating system includes the kernel and outer layer applications. Different Linux distributions use the same kernel and different outer layer applications. Common Linux distributions are Ubuntu , red hat , SuSE , Gentoo , CentOS and Debian . Shell is the interface between the linux kernel and the user. Get Linux Install Ubuntu in a virtual environment. Not suggested to novices. Buy a Ubuntu. Apply for an account at the Institute\u2019s Supercomputer Center. This is the most common method. Log into Linux sever from Windows Download a Secure Shell (ssh) terminal. Common terminal: Xshell: https://www.xshellcn.com/ PuTTY: http://www.putty.org/ Install the shell terminal. Create a new session. Choose the ssh protocol and enter the host IP, port, user ID and password. Click connect . Log into Linux sever from Linux or Mac Type command in terminal: ssh [host IP:port]@[user ID] . Then enter the password. Basic knowledge of Linux The absolute path is identified by a forward slash ( / ), and the structure of directory is tree structure. How to use linux command: enter the command at the shell prompt: $ . Command like: [Path]/command [-option parameter] [file|directory] . For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz Enter a single dot ( . ) to indicate the current directory, and enter a double dot ( .. ) to indicate the parent directory of the current directory. For example: cd .. Use the man command to view the operation manual of all required commands. Command like: man [command name] . For example: man cp Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed. For example: ls -l my_file This command specifies the relevant information of the output file my_file. When writing a filter, you can use a question mark ( ? ) to represent a character, an asterisk ( * ) to represent zero or more characters, and use the tab key ( Tab ) to quickly complete the file name or directory first name. The which command is used to find the path of the command. Command like: which grep For example: which fastp About permission View the file permission When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining nine letters are grouped into three, representing the permissions for the owner, the owner s group, and other groups. r means read-only. w means allowing user to modify the content of the file. x means allowing user to execute the file as a program. - means having no such permission. Modify permissions: chmod command You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt Command about directory Check files which are in the directory list Basic list function: ls command Command like: ls various parameters directory name -F Distinguish between files and directories -R Recursive option to list files in subdirectories contained in the current directory -l Produces a long list of output results, including information about each file -d Lists only the information of the directory itself, not its contents -i The inode number of the file, which is the unique identifier of the file -a Display both hidden files and ordinary files -t Sort by time modified -h Show file size easy to read for human The parameters can be combined and written. For example: ls -ltrh . The way to output the tree list: tree tool The tool needs to be installed by yourself. Command like: tree ./ . Create a directory: mkdir command Command like: mkdir [directory name] To create multiple directories and subdirectories, you can use the -p parameter. For example: mkdir -p New_file/work/file1 . The -p parameter in the mkdir command can create missing parent directories as needed. Delete directory: rmdir command Command like: rmdir [-option parameter] [directory name] - -No Parameters after rmdir delete empty directories - -rf Delete all contents in the directory - -i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct. Switch the directory: cd command Command like: cd directory For example: cd /usr/bin View the current absolute path of current directory Command like: pwd Command about file Create a file: touch command Command like: touch [-option parameter] [file name] - Create a new file without adding parameters after touch, if the file already exists, change the modification time. - -a Change the access time of an existing file Delete files: rm command Command like: rm -i [file name] Because Linux does not have a recycle bin, you must add the -i parameter to avoid errors when deleting. Copy files: cp command Command like: cp [-option parameter] [file name] - -i Force to ask if you need to overwrite existing files - -R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter Rename and move files: mv command Rename Command like: mv [original file name] [new file name] Move Command like: mv [file name in the original path] [target new path] Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook . Move the book file in the picture folder to the file folder, and rename it to cook . View files View file type: file command Command like: file [file name] You can check the file type, character encoding method, whether the file can be run, etc. View the entire file content cat command: display all data in the text file Command like: cat [-option parameter] [file name] No parameters after cat means display content. -n Display content after adding line number. -b Displays only after adding line numbers to text content. -T Does not display tabs, replace tabs with ^T to display. more command: display the content of the text file, but it will stop after each page is displayed. less command: display the content of text files and support more advanced interaction. View a part of file content head command: view the beginning of the file Command like: head -n file name n is the number of rows displayed tail command: view the end of the file Command like: tail -n file name n is the number of rows displayed Upload files, download files rz : upload file sz [file name] : download file Command about process Probe the process ps command command like: ps [-option parameter] Symbol description: PID : Process ID. TTY : Terminal device when process starts. TIME : Cumulative CPU time required by the process. CMD : The name of the command used. top command Command like: top Symbol description: load average : The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. PR : Process priority NI : Moderate value of process VIRT : The total amount of virtual memory occupied by the process RES : The total amount of physical memory occupied by process. MEM : The ratio of memory used by the process to available memory. S : Process state ( D : interruptible sleep state; R : running; S : sleeping; T : tracking or stopping state; Z : rigid state). The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information. End the process kill command command like: kill PID or kill -s [process signal] killall command Command like: killall [process name] Use wildcards carefully in the killall command Command about task Execute tasks to the background [Path]/command [-option parameter] [file|directory] & nohup [path]/command [-option parameter] [file|directory] & screen command, command like : Create a screen: screen -dmS screen_test View the screen: screen -list Connect to the screen: screen -r screen_test Common task management commands: jobs : View tasks, return task number n and process number bg %n : Transfer task number n to the background fg %n : Transfer task number n to the foreground ctrl+z : Suspend the current task ctrl+c : Stop the current task kill -n task : End the task Command about disk space Mount the device: mount command Command like: mount parameter file device type device to be mounted target location File device types are: - -vfat : Windows long file system - -ntfs : An advanced file system widely used in Windows - -iso9660 : Standard CD-ROM file system Uninstall the device: umount command Command like: umount location/target device Explore the disk situation df command Command like: df [-option parameter] [target disk] du command Command like: du [-option parameter] [target disk] -c Displays the total size of all listed files -h Display in a user-readable way -s Displays the total of each output parameter The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file Disk partition: fdisk command Command like: fdisk -l [disk name] Disk formatting: mkfs command Command like: mksf -t file [system format] [-option parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat Disk verification: fsck command Command like: fsck -t file [system format] [-option parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat Bioinformatics on linux cases 1: install software Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz Install the software: cd soft ./configure make make install Update PATH: Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH Update environment variables: source ~/.bashrc 2: download data from database wget command Command like: wget [-option parameter] [URL] -c When connection has been cut off,you can use this parameter to resume the transfer. -i When there are multiple files to download, you can write the URL of each file in a download.txt. Then type command: wget -i download.txt . -r Download all files from this website including all addresses pointed to by the site. For example: wget [https://www.ncbi.nlm.nih.gov/sra/SRR8467693](https://www.ncbi.nlm.nih.gov/sra/SRR8467693) sratoolkit Install sratoolkit Write command like: module load sratoolkit prefetch SRR8467686 3: fastq-dump Command like: fastq-dump [-option parameter] - --split-spot : Split paired-end sequencing into two copies, but put them in the same file - --split-files : Divide paired-end sequencing into two copies and put them in different files, but discard the reads that one party has but one does not. - --split-3 : Divide the paired-end sequencing into two copies and put them in different files, but the reads that one party has and the other does not will be put in a separate folder - -o Output path","title":"Linux & shell basic"},{"location":"linux/#shell-and-linux","text":"Author: Hanrui Bai, 2021-2-15","title":"Shell and Linux"},{"location":"linux/#about-linux","text":"The complete Linux operating system includes the kernel and outer layer applications. Different Linux distributions use the same kernel and different outer layer applications. Common Linux distributions are Ubuntu , red hat , SuSE , Gentoo , CentOS and Debian . Shell is the interface between the linux kernel and the user.","title":"About Linux"},{"location":"linux/#get-linux","text":"Install Ubuntu in a virtual environment. Not suggested to novices. Buy a Ubuntu. Apply for an account at the Institute\u2019s Supercomputer Center. This is the most common method.","title":"Get Linux"},{"location":"linux/#log-into-linux-sever-from-windows","text":"Download a Secure Shell (ssh) terminal. Common terminal: Xshell: https://www.xshellcn.com/ PuTTY: http://www.putty.org/ Install the shell terminal. Create a new session. Choose the ssh protocol and enter the host IP, port, user ID and password. Click connect .","title":"Log into Linux sever from Windows"},{"location":"linux/#log-into-linux-sever-from-linux-or-mac","text":"Type command in terminal: ssh [host IP:port]@[user ID] . Then enter the password.","title":"Log into Linux sever from Linux or Mac"},{"location":"linux/#basic-knowledge-of-linux","text":"The absolute path is identified by a forward slash ( / ), and the structure of directory is tree structure. How to use linux command: enter the command at the shell prompt: $ . Command like: [Path]/command [-option parameter] [file|directory] . For example: ~/miniconda3/envs/RNA/bin/fastp -i /home/sysbio/SRR8467686.fastq.gz Enter a single dot ( . ) to indicate the current directory, and enter a double dot ( .. ) to indicate the parent directory of the current directory. For example: cd .. Use the man command to view the operation manual of all required commands. Command like: man [command name] . For example: man cp Filter: The filter refers to the name of the specified file and is used after many commands. Add a filter after the ls command, then only the information of the file will be displayed. For example: ls -l my_file This command specifies the relevant information of the output file my_file. When writing a filter, you can use a question mark ( ? ) to represent a character, an asterisk ( * ) to represent zero or more characters, and use the tab key ( Tab ) to quickly complete the file name or directory first name. The which command is used to find the path of the command. Command like: which grep For example: which fastp","title":"Basic knowledge of Linux"},{"location":"linux/#about-permission","text":"","title":"About permission"},{"location":"linux/#view-the-file-permission","text":"When you use ls -l command, the permissions will be marked at the beginning of the file, like: drwxrwxrwx. The first letter represents the type of file: d means directory, - means file, and l means soft link. The remaining nine letters are grouped into three, representing the permissions for the owner, the owner s group, and other groups. r means read-only. w means allowing user to modify the content of the file. x means allowing user to execute the file as a program. - means having no such permission.","title":"View the file permission"},{"location":"linux/#modify-permissions-chmod-command","text":"You must have the authority to operate files Command like: chmod (user permissions) (group permissions) (other permissions) file Permission is expressed in octal code: r=4, w=2, x=1 For example: chmod 755 test.txt The result is -rwxr-xr-x test.txt","title":"Modify permissions: chmod command"},{"location":"linux/#command-about-directory","text":"","title":"Command about directory"},{"location":"linux/#check-files-which-are-in-the-directory-list","text":"Basic list function: ls command Command like: ls various parameters directory name -F Distinguish between files and directories -R Recursive option to list files in subdirectories contained in the current directory -l Produces a long list of output results, including information about each file -d Lists only the information of the directory itself, not its contents -i The inode number of the file, which is the unique identifier of the file -a Display both hidden files and ordinary files -t Sort by time modified -h Show file size easy to read for human The parameters can be combined and written. For example: ls -ltrh . The way to output the tree list: tree tool The tool needs to be installed by yourself. Command like: tree ./ .","title":"Check files which are in the directory list"},{"location":"linux/#create-a-directory-mkdir-command","text":"Command like: mkdir [directory name] To create multiple directories and subdirectories, you can use the -p parameter. For example: mkdir -p New_file/work/file1 . The -p parameter in the mkdir command can create missing parent directories as needed.","title":"Create a directory: mkdir command"},{"location":"linux/#delete-directory-rmdir-command","text":"Command like: rmdir [-option parameter] [directory name] - -No Parameters after rmdir delete empty directories - -rf Delete all contents in the directory - -i Ask a question before deleting Because Linux does not have a recycle bin, you must add the -i parameter when deleting to confirm whether the deleted content is correct.","title":"Delete directory: rmdir command"},{"location":"linux/#switch-the-directory-cd-command","text":"Command like: cd directory For example: cd /usr/bin","title":"Switch the directory: cd command"},{"location":"linux/#view-the-current-absolute-path-of-current-directory","text":"Command like: pwd","title":"View the current absolute path of current directory"},{"location":"linux/#command-about-file","text":"","title":"Command about file"},{"location":"linux/#create-a-file-touch-command","text":"Command like: touch [-option parameter] [file name] - Create a new file without adding parameters after touch, if the file already exists, change the modification time. - -a Change the access time of an existing file","title":"Create a file: touch command"},{"location":"linux/#delete-files-rm-command","text":"Command like: rm -i [file name] Because Linux does not have a recycle bin, you must add the -i parameter to avoid errors when deleting.","title":"Delete files: rm command"},{"location":"linux/#copy-files-cp-command","text":"Command like: cp [-option parameter] [file name] - -i Force to ask if you need to overwrite existing files - -R Copy the entire directory recursively To avoid errors, it is recommended to add the -i parameter","title":"Copy files: cp command"},{"location":"linux/#rename-and-move-files-mv-command","text":"Rename Command like: mv [original file name] [new file name] Move Command like: mv [file name in the original path] [target new path] Rename and move operations can be performed at the same time For example: mv /home/picture/book /home/file/cook . Move the book file in the picture folder to the file folder, and rename it to cook .","title":"Rename and move files: mv command"},{"location":"linux/#view-files","text":"","title":"View files"},{"location":"linux/#view-file-type-file-command","text":"Command like: file [file name] You can check the file type, character encoding method, whether the file can be run, etc.","title":"View file type: file command"},{"location":"linux/#view-the-entire-file-content","text":"cat command: display all data in the text file Command like: cat [-option parameter] [file name] No parameters after cat means display content. -n Display content after adding line number. -b Displays only after adding line numbers to text content. -T Does not display tabs, replace tabs with ^T to display. more command: display the content of the text file, but it will stop after each page is displayed. less command: display the content of text files and support more advanced interaction.","title":"View the entire file content"},{"location":"linux/#view-a-part-of-file-content","text":"head command: view the beginning of the file Command like: head -n file name n is the number of rows displayed tail command: view the end of the file Command like: tail -n file name n is the number of rows displayed","title":"View a part of file content"},{"location":"linux/#upload-files-download-files","text":"rz : upload file sz [file name] : download file","title":"Upload files, download files"},{"location":"linux/#command-about-process","text":"","title":"Command about process"},{"location":"linux/#probe-the-process","text":"ps command command like: ps [-option parameter] Symbol description: PID : Process ID. TTY : Terminal device when process starts. TIME : Cumulative CPU time required by the process. CMD : The name of the command used. top command Command like: top Symbol description: load average : The three values are the average load of the last 1min, 5min, and 15min. The larger the value, the larger the load, and the more than 2 indicates the system is busy. PR : Process priority NI : Moderate value of process VIRT : The total amount of virtual memory occupied by the process RES : The total amount of physical memory occupied by process. MEM : The ratio of memory used by the process to available memory. S : Process state ( D : interruptible sleep state; R : running; S : sleeping; T : tracking or stopping state; Z : rigid state). The difference between ps and top command The ps command displays information at a specific time point, and the top command displays real-time information.","title":"Probe the process"},{"location":"linux/#end-the-process","text":"kill command command like: kill PID or kill -s [process signal] killall command Command like: killall [process name] Use wildcards carefully in the killall command","title":"End the process"},{"location":"linux/#command-about-task","text":"","title":"Command about task"},{"location":"linux/#execute-tasks-to-the-background","text":"[Path]/command [-option parameter] [file|directory] & nohup [path]/command [-option parameter] [file|directory] & screen command, command like : Create a screen: screen -dmS screen_test View the screen: screen -list Connect to the screen: screen -r screen_test","title":"Execute tasks to the background"},{"location":"linux/#common-task-management-commands","text":"jobs : View tasks, return task number n and process number bg %n : Transfer task number n to the background fg %n : Transfer task number n to the foreground ctrl+z : Suspend the current task ctrl+c : Stop the current task kill -n task : End the task","title":"Common task management commands:"},{"location":"linux/#command-about-disk-space","text":"","title":"Command about disk space"},{"location":"linux/#mount-the-device-mount-command","text":"Command like: mount parameter file device type device to be mounted target location File device types are: - -vfat : Windows long file system - -ntfs : An advanced file system widely used in Windows - -iso9660 : Standard CD-ROM file system","title":"Mount the device: mount command"},{"location":"linux/#uninstall-the-device-umount-command","text":"Command like: umount location/target device","title":"Uninstall the device: umount command"},{"location":"linux/#explore-the-disk-situation","text":"df command Command like: df [-option parameter] [target disk] du command Command like: du [-option parameter] [target disk] -c Displays the total size of all listed files -h Display in a user-readable way -s Displays the total of each output parameter The difference between df and du commands The df command displays the disk usage, the du command displays the disk usage of each file Disk partition: fdisk command Command like: fdisk -l [disk name] Disk formatting: mkfs command Command like: mksf -t file [system format] [-option parameter] [disk name] File system formats are: mkfs.cramfs, mkfs.ext2, mkfs.ext3, mkfs.msdos, mkfs.vfat Disk verification: fsck command Command like: fsck -t file [system format] [-option parameter] [disk name] File system formats are: fsck.cramfs, fsck.ext2, fsck.ext3, fsck.msdos, fsck.vfat","title":"Explore the disk situation"},{"location":"linux/#bioinformatics-on-linux-cases","text":"","title":"Bioinformatics on linux cases"},{"location":"linux/#1-install-software","text":"Download software: wget \u2013c ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.6.0+-x64-linux.tar.gz Unzip file: tar zxvf ncbi-blast-2.6.0+-x64-linux.tar.gz Install the software: cd soft ./configure make make install Update PATH: Add the ./ncbi-blast-2.6.0+/bin directory to the environment variables: vim ~/.bashrc Add the following statement, save and exit: export PATH=./ncbi-blast-2.6.0+/bin:$PATH Update environment variables: source ~/.bashrc","title":"1: install software"},{"location":"linux/#2-download-data-from-database","text":"wget command Command like: wget [-option parameter] [URL] -c When connection has been cut off,you can use this parameter to resume the transfer. -i When there are multiple files to download, you can write the URL of each file in a download.txt. Then type command: wget -i download.txt . -r Download all files from this website including all addresses pointed to by the site. For example: wget [https://www.ncbi.nlm.nih.gov/sra/SRR8467693](https://www.ncbi.nlm.nih.gov/sra/SRR8467693) sratoolkit Install sratoolkit Write command like: module load sratoolkit prefetch SRR8467686","title":"2: download data from database"},{"location":"linux/#3-fastq-dump","text":"Command like: fastq-dump [-option parameter] - --split-spot : Split paired-end sequencing into two copies, but put them in the same file - --split-files : Divide paired-end sequencing into two copies and put them in different files, but discard the reads that one party has but one does not. - --split-3 : Divide the paired-end sequencing into two copies and put them in different files, but the reads that one party has and the other does not will be put in a separate folder - -o Output path","title":"3: fastq-dump"},{"location":"ngs/","text":"NGS analysis Table of Contents: RNASeq ChipSeq RNA-Seq analysis Chip-Seq analysis","title":"NGS analysis"},{"location":"ngs/#ngs-analysis","text":"Table of Contents: RNASeq ChipSeq","title":"NGS analysis"},{"location":"ngs/#rna-seq-analysis","text":"","title":"RNA-Seq analysis "},{"location":"ngs/#chip-seq-analysis","text":"","title":"Chip-Seq analysis "}]}